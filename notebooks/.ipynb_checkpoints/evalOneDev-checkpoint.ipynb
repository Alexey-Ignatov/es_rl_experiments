{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf # pylint: ignore-module\n",
    "import builtins\n",
    "import functools\n",
    "import copy\n",
    "import os\n",
    "\n",
    "# ================================================================\n",
    "# Import all names into common namespace\n",
    "# ================================================================\n",
    "\n",
    "clip = tf.clip_by_value\n",
    "\n",
    "# Make consistent with numpy\n",
    "# ----------------------------------------\n",
    "\n",
    "def sum(x, axis=None, keepdims=False):\n",
    "    return tf.reduce_sum(x, reduction_indices=None if axis is None else [axis], keep_dims = keepdims)\n",
    "def mean(x, axis=None, keepdims=False):\n",
    "    return tf.reduce_mean(x, reduction_indices=None if axis is None else [axis], keep_dims = keepdims)\n",
    "def var(x, axis=None, keepdims=False):\n",
    "    meanx = mean(x, axis=axis, keepdims=keepdims)\n",
    "    return mean(tf.square(x - meanx), axis=axis, keepdims=keepdims)\n",
    "def std(x, axis=None, keepdims=False):\n",
    "    return tf.sqrt(var(x, axis=axis, keepdims=keepdims))\n",
    "def max(x, axis=None, keepdims=False):\n",
    "    return tf.reduce_max(x, reduction_indices=None if axis is None else [axis], keep_dims = keepdims)\n",
    "def min(x, axis=None, keepdims=False):\n",
    "    return tf.reduce_min(x, reduction_indices=None if axis is None else [axis], keep_dims = keepdims)\n",
    "def concatenate(arrs, axis=0):\n",
    "    return tf.concat(axis, arrs)\n",
    "def argmax(x, axis=None):\n",
    "    return tf.argmax(x, dimension=axis)\n",
    "\n",
    "def switch(condition, then_expression, else_expression):\n",
    "    '''Switches between two operations depending on a scalar value (int or bool).\n",
    "    Note that both `then_expression` and `else_expression`\n",
    "    should be symbolic tensors of the *same shape*.\n",
    "\n",
    "    # Arguments\n",
    "        condition: scalar tensor.\n",
    "        then_expression: TensorFlow operation.\n",
    "        else_expression: TensorFlow operation.\n",
    "    '''\n",
    "    x_shape = copy.copy(then_expression.get_shape())\n",
    "    x = tf.cond(tf.cast(condition, 'bool'),\n",
    "                lambda: then_expression,\n",
    "                lambda: else_expression)\n",
    "    x.set_shape(x_shape)\n",
    "    return x\n",
    "\n",
    "# Extras\n",
    "# ----------------------------------------\n",
    "def l2loss(params):\n",
    "    if len(params) == 0:\n",
    "        return tf.constant(0.0)\n",
    "    else:\n",
    "        return tf.add_n([sum(tf.square(p)) for p in params])\n",
    "def lrelu(x, leak=0.2):\n",
    "    f1 = 0.5 * (1 + leak)\n",
    "    f2 = 0.5 * (1 - leak)\n",
    "    return f1 * x + f2 * abs(x)\n",
    "def categorical_sample_logits(X):\n",
    "    # https://github.com/tensorflow/tensorflow/issues/456\n",
    "    U = tf.random_uniform(tf.shape(X))\n",
    "    return argmax(X - tf.log(-tf.log(U)), axis=1)\n",
    "\n",
    "# ================================================================\n",
    "# Global session\n",
    "# ================================================================\n",
    "\n",
    "def get_session():\n",
    "    return tf.get_default_session()\n",
    "\n",
    "def single_threaded_session():\n",
    "    tf_config = tf.ConfigProto(\n",
    "        inter_op_parallelism_threads=1,\n",
    "        intra_op_parallelism_threads=1)\n",
    "    return tf.Session(config=tf_config)\n",
    "\n",
    "ALREADY_INITIALIZED = set()\n",
    "def initialize():\n",
    "    new_variables = set(tf.all_variables()) - ALREADY_INITIALIZED\n",
    "    get_session().run(tf.initialize_variables(new_variables))\n",
    "    ALREADY_INITIALIZED.update(new_variables)\n",
    "\n",
    "\n",
    "def eval(expr, feed_dict=None):\n",
    "    if feed_dict is None: feed_dict = {}\n",
    "    return get_session().run(expr, feed_dict=feed_dict)\n",
    "\n",
    "def set_value(v, val):\n",
    "    get_session().run(v.assign(val))\n",
    "\n",
    "def load_state(fname):\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(get_session(), fname)\n",
    "\n",
    "def save_state(fname):\n",
    "    os.makedirs(os.path.dirname(fname), exist_ok=True)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(get_session(), fname)\n",
    "\n",
    "# ================================================================\n",
    "# Model components\n",
    "# ================================================================\n",
    "\n",
    "\n",
    "def normc_initializer(std=1.0):\n",
    "    def _initializer(shape, dtype=None, partition_info=None): #pylint: disable=W0613\n",
    "        out = np.random.randn(*shape).astype(np.float32)\n",
    "        out *= std / np.sqrt(np.square(out).sum(axis=0, keepdims=True))\n",
    "        return tf.constant(out)\n",
    "    return _initializer\n",
    "\n",
    "def dense(x, size, name, weight_init=None, bias=True):\n",
    "    w = tf.get_variable(name + \"/w\", [x.get_shape()[1], size], initializer=weight_init)\n",
    "    ret = tf.matmul(x, w)\n",
    "    if bias:\n",
    "        b = tf.get_variable(name + \"/b\", [size], initializer=tf.zeros_initializer)\n",
    "        return ret + b\n",
    "    else:\n",
    "        return ret\n",
    "\n",
    "# ================================================================\n",
    "# Basic Stuff\n",
    "# ================================================================\n",
    "\n",
    "def function(inputs, outputs, updates=None, givens=None):\n",
    "    if isinstance(outputs, list):\n",
    "        return _Function(inputs, outputs, updates, givens=givens)\n",
    "    elif isinstance(outputs, dict):\n",
    "        f = _Function(inputs, outputs.values(), updates, givens=givens)\n",
    "        return lambda *inputs : dict(zip(outputs.keys(), f(*inputs)))\n",
    "    else:\n",
    "        f = _Function(inputs, [outputs], updates, givens=givens)\n",
    "        return lambda *inputs : f(*inputs)[0]\n",
    "\n",
    "class _Function(object):\n",
    "    def __init__(self, inputs, outputs, updates, givens, check_nan=False):\n",
    "        assert all(len(i.op.inputs)==0 for i in inputs), \"inputs should all be placeholders\"\n",
    "        self.inputs = inputs\n",
    "        updates = updates or []\n",
    "        self.update_group = tf.group(*updates)\n",
    "        self.outputs_update = list(outputs) + [self.update_group]\n",
    "        self.givens = {} if givens is None else givens\n",
    "        self.check_nan = check_nan\n",
    "    def __call__(self, *inputvals):\n",
    "        assert len(inputvals) == len(self.inputs)\n",
    "        feed_dict = dict(zip(self.inputs, inputvals))\n",
    "        feed_dict.update(self.givens)\n",
    "        results = get_session().run(self.outputs_update, feed_dict=feed_dict)[:-1]\n",
    "        if self.check_nan:\n",
    "            if any(np.isnan(r).any() for r in results):\n",
    "                raise RuntimeError(\"Nan detected\")\n",
    "        return results\n",
    "\n",
    "# ================================================================\n",
    "# Graph traversal\n",
    "# ================================================================\n",
    "\n",
    "VARIABLES = {}\n",
    "\n",
    "# ================================================================\n",
    "# Flat vectors\n",
    "# ================================================================\n",
    "\n",
    "def var_shape(x):\n",
    "    out = [k.value for k in x.get_shape()]\n",
    "    assert all(isinstance(a, int) for a in out), \\\n",
    "        \"shape function assumes that shape is fully known\"\n",
    "    return out\n",
    "\n",
    "def numel(x):\n",
    "    return intprod(var_shape(x))\n",
    "\n",
    "def intprod(x):\n",
    "    return int(np.prod(x))\n",
    "\n",
    "def flatgrad(loss, var_list):\n",
    "    grads = tf.gradients(loss, var_list)\n",
    "    return tf.concat(0, [tf.reshape(grad, [numel(v)])\n",
    "        for (v, grad) in zip(var_list, grads)])\n",
    "\n",
    "class SetFromFlat(object):\n",
    "    def __init__(self, var_list, dtype=tf.float32):\n",
    "        assigns = []\n",
    "        shapes = list(map(var_shape, var_list))\n",
    "        total_size = np.sum([intprod(shape) for shape in shapes])\n",
    "\n",
    "        self.theta = theta = tf.placeholder(dtype,[total_size])\n",
    "        start=0\n",
    "        assigns = []\n",
    "        for (shape,v) in zip(shapes,var_list):\n",
    "            size = intprod(shape)\n",
    "            assigns.append(tf.assign(v, tf.reshape(theta[start:start+size],shape)))\n",
    "            start+=size\n",
    "        assert start == total_size\n",
    "        self.op = tf.group(*assigns)\n",
    "    def __call__(self, theta):\n",
    "        get_session().run(self.op, feed_dict={self.theta:theta})\n",
    "\n",
    "class GetFlat(object):\n",
    "    def __init__(self, var_list):\n",
    "        self.op = tf.concat(0, [tf.reshape(v, [numel(v)]) for v in var_list])\n",
    "    def __call__(self):\n",
    "        return get_session().run(self.op)\n",
    "\n",
    "# ================================================================\n",
    "# Misc\n",
    "# ================================================================\n",
    "\n",
    "def scope_vars(scope, trainable_only):\n",
    "    \"\"\"\n",
    "    Get variables inside a scope\n",
    "    The scope can be specified as a string\n",
    "    \"\"\"\n",
    "    return tf.get_collection(\n",
    "        tf.GraphKeys.TRAINABLE_VARIABLES if trainable_only else tf.GraphKeys.VARIABLES,\n",
    "        scope=scope if isinstance(scope, str) else scope.name\n",
    "    )\n",
    "\n",
    "def in_session(f):\n",
    "    @functools.wraps(f)\n",
    "    def newfunc(*args, **kwargs):\n",
    "        with tf.Session():\n",
    "            f(*args, **kwargs)\n",
    "    return newfunc\n",
    "\n",
    "\n",
    "_PLACEHOLDER_CACHE = {} # name -> (placeholder, dtype, shape)\n",
    "def get_placeholder(name, dtype, shape):\n",
    "    print(\"calling get_placeholder\", name)\n",
    "    if name in _PLACEHOLDER_CACHE:\n",
    "        out, dtype1, shape1 = _PLACEHOLDER_CACHE[name]\n",
    "        assert dtype1==dtype and shape1==shape\n",
    "        return out\n",
    "    else:\n",
    "        out = tf.placeholder(dtype=dtype, shape=shape, name=name)\n",
    "        _PLACEHOLDER_CACHE[name] = (out,dtype,shape)\n",
    "        return out\n",
    "def get_placeholder_cached(name):\n",
    "    return _PLACEHOLDER_CACHE[name][0]\n",
    "\n",
    "def flattenallbut0(x):\n",
    "    return tf.reshape(x, [-1, intprod(x.get_shape().as_list()[1:])])\n",
    "\n",
    "def reset():\n",
    "    global _PLACEHOLDER_CACHE\n",
    "    global VARIABLES\n",
    "    _PLACEHOLDER_CACHE = {}\n",
    "    VARIABLES = {}\n",
    "    tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_session(single_threaded):\n",
    "    import tensorflow as tf\n",
    "    if not single_threaded:\n",
    "        return tf.InteractiveSession()\n",
    "    return tf.InteractiveSession(config=tf.ConfigProto(inter_op_parallelism_threads=1, intra_op_parallelism_threads=1))\n",
    "\n",
    "sess = make_session(single_threaded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from random import sample as rsample\n",
    "#from . import tf_util as U\n",
    "\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class Policy:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.args, self.kwargs = args, kwargs\n",
    "        self.scope = self._initialize(*args, **kwargs)\n",
    "        self.all_variables = tf.get_collection(tf.GraphKeys.VARIABLES, self.scope.name)\n",
    "\n",
    "        self.trainable_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, self.scope.name)\n",
    "        #self.num_params = sum(int(np.prod(v.get_shape().as_list())) for v in self.trainable_variables)\n",
    "        self._setfromflat = SetFromFlat(self.trainable_variables)\n",
    "        self._getflat = GetFlat(self.trainable_variables)\n",
    "\n",
    "        #logger.info('Trainable variables ({} parameters)'.format(self.num_params))\n",
    "        for v in self.trainable_variables:\n",
    "            shp = v.get_shape().as_list()\n",
    "            logger.info('- {} shape:{} size:{}'.format(v.name, shp, np.prod(shp)))\n",
    "        logger.info('All variables')\n",
    "        for v in self.all_variables:\n",
    "            shp = v.get_shape().as_list()\n",
    "            logger.info('- {} shape:{} size:{}'.format(v.name, shp, np.prod(shp)))\n",
    "\n",
    "        placeholders = [tf.placeholder(v.value().dtype, v.get_shape().as_list()) for v in self.all_variables]\n",
    "        self.set_all_vars = function(\n",
    "            inputs=placeholders,\n",
    "            outputs=[],\n",
    "            updates=[tf.group(*[v.assign(p) for v, p in zip(self.all_variables, placeholders)])]\n",
    "        )\n",
    "\n",
    "    def _initialize(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def save(self, filename):\n",
    "        assert filename.endswith('.h5')\n",
    "        with h5py.File(filename, 'w') as f:\n",
    "            for v in self.all_variables:\n",
    "                f[v.name] = v.eval()\n",
    "            # TODO: it would be nice to avoid pickle, but it's convenient to pass Python objects to _initialize\n",
    "            # (like Gym spaces or numpy arrays)\n",
    "            f.attrs['name'] = type(self).__name__\n",
    "            f.attrs['args_and_kwargs'] = np.void(pickle.dumps((self.args, self.kwargs), protocol=-1))\n",
    "\n",
    "    @classmethod\n",
    "    def Load(cls, filename, extra_kwargs=None):\n",
    "        with h5py.File(filename, 'r') as f:\n",
    "            args, kwargs = pickle.loads(f.attrs['args_and_kwargs'].tostring())\n",
    "            if extra_kwargs:\n",
    "                kwargs.update(extra_kwargs)\n",
    "            policy = cls(*args, **kwargs)\n",
    "            policy.set_all_vars(*[f[v.name][...] for v in policy.all_variables])\n",
    "        return policy\n",
    "\n",
    "    # === Rollouts/training ===\n",
    "\n",
    "    def rollout(self, env, *, render=False, timestep_limit=None, save_obs=False, random_stream=None, silent = True, trNo = 10):\n",
    "        \"\"\"\n",
    "        If random_stream is provided, the rollout will take noisy actions with noise drawn from that stream.\n",
    "        Otherwise, no action noise will be added.\n",
    "        \"\"\"\n",
    "        env_timestep_limit = GRID_SIZE - 2\n",
    "        timestep_limit = env_timestep_limit if timestep_limit is None else min(timestep_limit, env_timestep_limit)\n",
    "        rews = []\n",
    "        t = 0\n",
    "        \n",
    "        assert env.isOffPolisy()\n",
    "        \n",
    "        trajWeightedReards = []\n",
    "        meanAcStd = 1.\n",
    "        for i in range(trNo):\n",
    "            traj = env.get_trajectory()\n",
    "            cumProbRel = 1.\n",
    "            \n",
    "            weightedReward = 0\n",
    "            netsActions = []\n",
    "            for step_no in range(timestep_limit):\n",
    "                ob, teacherAction, rew = traj[step_no]\n",
    "                ac = self.act(ob[None], random_stream=random_stream)[0]\n",
    "                \n",
    "                netsActions.append(ac)\n",
    "                \n",
    "                \n",
    "            meanAcStd = np.mean(np.std(netsActions, 1))\n",
    "            netsActions = [(action - np.mean(action))/meanAcStd for action in netsActions]\n",
    "            \n",
    "            for step_no in range(timestep_limit):  \n",
    "                ob, teacherAction, rew = traj[step_no]\n",
    "                ac = netsActions[step_no]\n",
    "                \n",
    "                polAcDistr = np.exp(ac)/np.sum(np.exp(ac))\n",
    "                teacherAcDistr = np.array([0.33]*3)\n",
    "                \n",
    "                actionRel  = polAcDistr[teacherAction] / teacherAcDistr[teacherAction]\n",
    "                \n",
    "                cumProbRel*= actionRel\n",
    "                weightedReward += actionRel*rew\n",
    "                \n",
    "                if not silent:\n",
    "                    print(ac, 'action_ofnet')\n",
    "                    print(polAcDistr, 'action_ofnet_proba')\n",
    "                    print(cumProbRel, 'cumProbRel')\n",
    "                    if step_no == timestep_limit-1:\n",
    "                        print(actionRel, 'actionRel', rew, 'rew', weightedReward, 'weightedReward')\n",
    "                   \n",
    "            if not silent:\n",
    "                print(meanAcStd, 'meanAcStd')\n",
    "                print('------------------------------------------------')\n",
    "                \n",
    "\n",
    "            trajWeightedReards.append(weightedReward)\n",
    "            \n",
    "            \n",
    "        return np.array([np.mean(trajWeightedReards)]) , timestep_limit\n",
    "\n",
    "    def act(self, ob, random_stream=None):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def set_trainable_flat(self, x):\n",
    "        self._setfromflat(x)\n",
    "\n",
    "    def get_trainable_flat(self):\n",
    "        return self._getflat()\n",
    "\n",
    "    @property\n",
    "    def needs_ob_stat(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def set_ob_stat(self, ob_mean, ob_std):\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.5,   9. ,  13.5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std([np.array([1, 2, 3]), np.array([10, 20, 30])], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "class CatchPolicy(Policy):\n",
    "    def _initialize(self, ob_space, ac_space, nonlin_type, hidden_dims, connection_type):\n",
    "        self.ac_space = ac_space\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.connection_type = connection_type\n",
    "\n",
    "        assert len(ob_space.shape) == len(self.ac_space.shape) == 1\n",
    "        #assert np.all(np.isfinite(self.ac_space.low)) and np.all(np.isfinite(self.ac_space.high)), \\\n",
    "        #    'Action bounds required'\n",
    "\n",
    "        self.nonlin = {'tanh': tf.tanh, 'relu': tf.nn.relu,  'elu': tf.nn.elu}[nonlin_type]\n",
    "\n",
    "        with tf.variable_scope(type(self).__name__) as scope:\n",
    "\n",
    "            # Policy network\n",
    "            o = tf.placeholder(tf.float32, [None] + list(ob_space.shape))\n",
    "            a = self._make_net(o)\n",
    "            self._act = function([o], a)\n",
    "        return scope\n",
    "\n",
    "    def _make_net(self, o):\n",
    "        # Process observation\n",
    "        if self.connection_type == 'ff':\n",
    "            x = o\n",
    "            for ilayer, hd in enumerate(self.hidden_dims):\n",
    "                x = self.nonlin(dense(x, hd, 'l{}'.format(ilayer), normc_initializer(1.0)))\n",
    "        else:\n",
    "            raise NotImplementedError(self.connection_type)\n",
    "\n",
    "        # Map to action\n",
    "        scores = dense(x, 3, 'out', normc_initializer(0.01))\n",
    "        #scores_nab = tf.reshape(scores, [-1, 1, 3])\n",
    "        #aidx_na =  tf.argmax(scores_nab, 2)  # 0 ... num_bins-1\n",
    "        a = tf.to_float(scores)\n",
    "        \n",
    "       \n",
    "        return a\n",
    "\n",
    "    def act(self, ob, random_stream=None):\n",
    "        return self._act(ob)\n",
    "\n",
    "    @property\n",
    "    def needs_ob_stat(self):\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def needs_ref_batch(self):\n",
    "        return False\n",
    "\n",
    "    def initialize_from(self, filename, ob_stat=None):\n",
    "        \"\"\"\n",
    "        Initializes weights from another policy, which must have the same architecture (variable names),\n",
    "        but the weight arrays can be smaller than the current policy.\n",
    "        \"\"\"\n",
    "        with h5py.File(filename, 'r') as f:\n",
    "            f_var_names = []\n",
    "            f.visititems(lambda name, obj: f_var_names.append(name) if isinstance(obj, h5py.Dataset) else None)\n",
    "            assert set(v.name for v in self.all_variables) == set(f_var_names), 'Variable names do not match'\n",
    "\n",
    "            init_vals = []\n",
    "            for v in self.all_variables:\n",
    "                shp = v.get_shape().as_list()\n",
    "                f_shp = f[v.name].shape\n",
    "                assert len(shp) == len(f_shp) and all(a >= b for a, b in zip(shp, f_shp)), \\\n",
    "                    'This policy must have more weights than the policy to load'\n",
    "                init_val = v.eval()\n",
    "                # ob_mean and ob_std are initialized with nan, so set them manually\n",
    "                if 'ob_mean' in v.name:\n",
    "                    init_val[:] = 0\n",
    "                    init_mean = init_val\n",
    "                elif 'ob_std' in v.name:\n",
    "                    init_val[:] = 0.001\n",
    "                    init_std = init_val\n",
    "                # Fill in subarray from the loaded policy\n",
    "                init_val[tuple([np.s_[:s] for s in f_shp])] = f[v.name]\n",
    "                init_vals.append(init_val)\n",
    "            self.set_all_vars(*init_vals)\n",
    "\n",
    "        if ob_stat is not None:\n",
    "            ob_stat.set_from_init(init_mean, init_std, init_count=1e5)\n",
    "            \n",
    "GRID_SIZE = 10            \n",
    "            \n",
    "class catcher():\n",
    "    def __init__(self):\n",
    "        self.memory = pickle.load(open('memoryList.pickle', 'rb'))\n",
    "        \n",
    "        self.observation_space = np.zeros((GRID_SIZE, GRID_SIZE)).ravel()\n",
    "        self.action_space = np.array([2])\n",
    "\n",
    "    def get_trajectory(self):\n",
    "        return rsample(self.memory, 1)[0]\n",
    "\n",
    "    def reset(self):\n",
    "        self.ep = episode()\n",
    "        S, won, _, _ = self.ep.__next__()\n",
    "        return S\n",
    "    def isOffPolisy(self):\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alexey/experiments/evolution-strategies-starter-master/es_distributed\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "c = catcher()\n",
    "c.get_trajectory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def save_img():\n",
    "    if 'images' not in os.listdir('.'):\n",
    "        os.mkdir('images')\n",
    "    frame = 0\n",
    "    while True:\n",
    "        screen = (yield)\n",
    "        plt.imshow(screen[0], interpolation='none')\n",
    "        plt.savefig('images/%03i.png' % frame)\n",
    "        frame += 1\n",
    "    \n",
    "img_saver = save_img()\n",
    "img_saver.next()\n",
    "\n",
    "for _ in xrange(8):\n",
    "    g = episode()\n",
    "    S, _ = g.next()\n",
    "    img_saver.send(S)\n",
    "    try:\n",
    "        while True:\n",
    "            act = np.argmax(model.predict(S[np.newaxis]), axis=-1)[0] - 1\n",
    "            S, _ = g.send(act)\n",
    "            img_saver.send(S)\n",
    "\n",
    "    except StopIteration:\n",
    "        pass\n",
    "\n",
    "img_saver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = catcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = CatchPolicy(env.observation_space ,env.action_space, 'tanh', [100, 100], 'ff')\n",
    "initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cp.initialize_from('/tmp/es_master_31842/snapshot_iter00900_rew1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.08756618]), 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.rollout(env,silent = True, trNo=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.46709239 -0.76010847  0.29301611] action_ofnet\n",
      "[ 0.46874753  0.13739547  0.39385703] action_ofnet_proba\n",
      "0.416349913135 cumProbRel\n",
      "[-0.27370858 -0.76967764  1.0433861 ] action_ofnet\n",
      "[ 0.18721184  0.11400837  0.6987797 ] action_ofnet_proba\n",
      "0.236198890551 cumProbRel\n",
      "[ 0.08484984 -0.80111551  0.7162658 ] action_ofnet\n",
      "[ 0.30371255  0.12522553  0.57106191] action_ofnet_proba\n",
      "0.0896307001093 cumProbRel\n",
      "[-0.37984625 -0.72580993  1.10565615] action_ofnet\n",
      "[ 0.16327272  0.11552168  0.72120565] action_ofnet_proba\n",
      "0.0443462076395 cumProbRel\n",
      "[-0.64233375 -0.79760706  1.43994081] action_ofnet\n",
      "[ 0.10122608  0.08666786  0.81210607] action_ofnet_proba\n",
      "0.0136030078978 cumProbRel\n",
      "[-1.01867652 -0.84933323  1.86800957] action_ofnet\n",
      "[ 0.04970597  0.05887805  0.89141595] action_ofnet_proba\n",
      "0.0367452674471 cumProbRel\n",
      "[-1.26991391 -0.69202179  1.96193552] action_ofnet\n",
      "[ 0.03557613  0.06340655  0.90101731] action_ofnet_proba\n",
      "0.00396137755265 cumProbRel\n",
      "[-1.26601958 -0.88036919  2.14638877] action_ofnet\n",
      "[ 0.03047963  0.04482245  0.92469788] action_ofnet_proba\n",
      "0.000365882844413 cumProbRel\n",
      "0.0923625278202 actionRel -1000 rew -0.365882844413 weightedReward\n",
      "0.0608466 meanAcStd\n",
      "------------------------------------------------\n",
      "[-0.17039914 -1.18469036  1.35508966] action_ofnet\n",
      "[ 0.16778384  0.06084839  0.77136779] action_ofnet_proba\n",
      "0.184389045744 cumProbRel\n",
      "[ 0.14701058 -1.27786112  1.13085055] action_ofnet\n",
      "[ 0.25541174  0.06143656  0.68315166] action_ofnet_proba\n",
      "0.0343279677576 cumProbRel\n",
      "[ 0.61166728 -1.49211633  0.88044888] action_ofnet\n",
      "[ 0.41146111  0.05019577  0.53834307] action_ofnet_proba\n",
      "0.0560006776243 cumProbRel\n",
      "[ 0.60868645 -1.08326805  0.4745816 ] action_ofnet\n",
      "[ 0.48575342  0.08945598  0.42479059] action_ofnet_proba\n",
      "0.0720865483167 cumProbRel\n",
      "[ 0.99330968 -1.25143611  0.2581265 ] action_ofnet\n",
      "[ 0.63076675  0.06683256  0.30240071] action_ofnet_proba\n",
      "0.137787265927 cumProbRel\n",
      "[ 1.0000695  -1.09662521  0.09655594] action_ofnet\n",
      "[ 0.65444791  0.08040669  0.26514542] action_ofnet_proba\n",
      "0.110708068596 cumProbRel\n",
      "[ 1.54582202 -1.16293097 -0.382891  ] action_ofnet\n",
      "[ 0.82511318  0.0549689   0.11991792] action_ofnet_proba\n",
      "0.276808140096 cumProbRel\n",
      "[ 1.55996799 -1.38012123 -0.1798467 ] action_ofnet\n",
      "[ 0.81405789  0.04303192  0.14291024] action_ofnet_proba\n",
      "0.119874903973 cumProbRel\n",
      "0.433061339638 actionRel 1000 rew 119.874903973 weightedReward\n",
      "0.0359041 meanAcStd\n",
      "------------------------------------------------\n",
      "[ 0.1873178  -1.06182659  0.8745085 ] action_ofnet\n",
      "[ 0.3053554   0.08756068  0.60708392] action_ofnet_proba\n",
      "0.925319393476 cumProbRel\n",
      "[ 0.09162214 -1.44842982  1.35680771] action_ofnet\n",
      "[ 0.21016704  0.0450535   0.74477953] action_ofnet_proba\n",
      "0.589307981154 cumProbRel\n",
      "[-0.04170181 -1.14237475  1.18407643] action_ofnet\n",
      "[ 0.21099435  0.07018667  0.71881902] action_ofnet_proba\n",
      "0.125338083362 cumProbRel\n",
      "[ 0.07612011 -1.31204772  1.23592746] action_ofnet\n",
      "[ 0.22528352  0.05621546  0.71850097] action_ofnet_proba\n",
      "0.0855654679197 cumProbRel\n",
      "[ 0.47299471 -1.13917077  0.66617602] action_ofnet\n",
      "[ 0.41449782  0.08267376  0.50282842] action_ofnet_proba\n",
      "0.107474848897 cumProbRel\n",
      "[ 1.2880559  -1.32907188  0.04101598] action_ofnet\n",
      "[ 0.7350961   0.05367104  0.2112329 ] action_ofnet_proba\n",
      "0.239407096814 cumProbRel\n",
      "[ 1.4740293  -1.14861202 -0.32541722] action_ofnet\n",
      "[ 0.80775362  0.05865165  0.13359469] action_ofnet_proba\n",
      "0.0425503690106 cumProbRel\n",
      "[ 1.52460766 -0.92536676 -0.5992409 ] action_ofnet\n",
      "[ 0.8292793   0.07156332  0.09915739] action_ofnet_proba\n",
      "0.106927698118 cumProbRel\n",
      "2.51296758652 actionRel 10000 rew 1069.27698118 weightedReward\n",
      "0.0412505 meanAcStd\n",
      "------------------------------------------------\n",
      "[ 0.9012813  -1.05830336  0.15702219] action_ofnet\n",
      "[ 0.61881071  0.08720091  0.29398841] action_ofnet_proba\n",
      "0.264245181373 cumProbRel\n",
      "[ 0.48124343 -1.2985357   0.81729233] action_ofnet\n",
      "[ 0.38939556  0.06568145  0.54492307] action_ofnet_proba\n",
      "0.31180576256 cumProbRel\n",
      "[ 0.76091945 -1.61697841  0.85605901] action_ofnet\n",
      "[ 0.45608833  0.04230007  0.50161159] action_ofnet_proba\n",
      "0.0399678936661 cumProbRel\n",
      "[ 0.74793386 -1.2447505   0.49681664] action_ofnet\n",
      "[ 0.52239501  0.07121758  0.40638736] action_ofnet_proba\n",
      "0.0632697830356 cumProbRel\n",
      "[ 1.01615095 -1.280213    0.26406217] action_ofnet\n",
      "[ 0.63613027  0.06401001  0.29985967] action_ofnet_proba\n",
      "0.121963104172 cumProbRel\n",
      "[ 1.02306628 -1.12184227  0.09877626] action_ofnet\n",
      "[ 0.66054916  0.07733627  0.26211452] action_ofnet_proba\n",
      "0.0968736396915 cumProbRel\n",
      "[ 1.58136845 -1.18967271 -0.39169565] action_ofnet\n",
      "[ 0.832205    0.05209336  0.11570163] action_ofnet_proba\n",
      "0.0152923448587 cumProbRel\n",
      "[ 1.59583974 -1.41185737 -0.1839823 ] action_ofnet\n",
      "[ 0.82096857  0.04056022  0.13847126] action_ofnet_proba\n",
      "0.0380440438332 cumProbRel\n",
      "2.48778354038 actionRel 1000 rew 38.0440438332 weightedReward\n",
      "0.035097 meanAcStd\n",
      "------------------------------------------------\n",
      "[ 0.08685116 -0.95170051  0.86484945] action_ofnet\n",
      "[ 0.28319973  0.10024334  0.61655694] action_ofnet_proba\n",
      "1.8683543711 cumProbRel\n",
      "[-0.35860199 -0.89291537  1.2515173 ] action_ofnet\n",
      "[ 0.15175706  0.08894049  0.7593025 ] action_ofnet_proba\n",
      "0.503552606936 cumProbRel\n",
      "[-0.2081776  -0.87537444  1.08355212] action_ofnet\n",
      "[ 0.19409107  0.09959687  0.70631212] action_ofnet_proba\n",
      "0.151976549251 cumProbRel\n",
      "[-0.16118039 -0.98045856  1.14163899] action_ofnet\n",
      "[ 0.19529702  0.08607709  0.7186259 ] action_ofnet_proba\n",
      "0.0899411116 cumProbRel\n",
      "[-0.59245747 -0.82736683  1.41982436] action_ofnet\n",
      "[ 0.10786312  0.08528116  0.80685574] action_ofnet_proba\n",
      "0.219907581792 cumProbRel\n",
      "[-0.99895054 -0.88192153  1.88087177] action_ofnet\n",
      "[ 0.05016238  0.05639014  0.89344752] action_ofnet_proba\n",
      "0.0375776319706 cumProbRel\n",
      "[-1.33409154 -1.04015768  2.37424946] action_ofnet\n",
      "[ 0.02318691  0.03110976  0.94570333] action_ofnet_proba\n",
      "0.00354251889797 cumProbRel\n",
      "[ 0.21570401 -0.86272126  0.6470173 ] action_ofnet\n",
      "[ 0.34729356  0.11812522  0.53458124] action_ofnet_proba\n",
      "0.00573867927073 cumProbRel\n",
      "1.61994316361 actionRel -1000 rew -5.73867927073 weightedReward\n",
      "0.052125 meanAcStd\n",
      "------------------------------------------------\n",
      "[ 0.46709239 -0.76010847  0.29301611] action_ofnet\n",
      "[ 0.46874753  0.13739547  0.39385703] action_ofnet_proba\n",
      "1.19350615776 cumProbRel\n",
      "[-0.27370858 -0.76967764  1.0433861 ] action_ofnet\n",
      "[ 0.18721184  0.11400837  0.6987797 ] action_ofnet_proba\n",
      "0.412332388255 cumProbRel\n",
      "[ 0.08484984 -0.80111551  0.7162658 ] action_ofnet\n",
      "[ 0.30371255  0.12522553  0.57106191] action_ofnet_proba\n",
      "0.713537335944 cumProbRel\n",
      "[-0.37984625 -0.72580993  1.10565615] action_ofnet\n",
      "[ 0.16327272  0.11552168  0.72120565] action_ofnet_proba\n",
      "1.55941563462 cumProbRel\n",
      "[-0.64233375 -0.79760706  1.43994081] action_ofnet\n",
      "[ 0.10122608  0.08666786  0.81210607] action_ofnet_proba\n",
      "0.478344019091 cumProbRel\n",
      "[-1.01867652 -0.84933323  1.86800957] action_ofnet\n",
      "[ 0.04970597  0.05887805  0.89141595] action_ofnet_proba\n",
      "1.29213178771 cumProbRel\n",
      "[-1.26991391 -0.69202179  1.96193552] action_ofnet\n",
      "[ 0.03557613  0.06340655  0.90101731] action_ofnet_proba\n",
      "0.248271569761 cumProbRel\n",
      "[-1.26601958 -0.88036919  2.14638877] action_ofnet\n",
      "[ 0.03047963  0.04482245  0.92469788] action_ofnet_proba\n",
      "0.69568543401 cumProbRel\n",
      "2.80211477569 actionRel -1000 rew -695.68543401 weightedReward\n",
      "0.0608466 meanAcStd\n",
      "------------------------------------------------\n",
      "[ 0.70548761 -1.27678299  0.57129544] action_ofnet\n",
      "[ 0.4969739   0.06846119  0.43456492] action_ofnet_proba\n",
      "1.31686338873 cumProbRel\n",
      "[ 0.3433753  -1.40713513  1.0637598 ] action_ofnet\n",
      "[ 0.30970219  0.0537907   0.63650709] action_ofnet_proba\n",
      "2.53997845039 cumProbRel\n",
      "[ 0.85222834 -1.13942289  0.28719443] action_ofnet\n",
      "[ 0.58657533  0.08004988  0.33337474] action_ofnet_proba\n",
      "2.56595349147 cumProbRel\n",
      "[ 0.34307247 -0.93095243  0.5878799 ] action_ofnet\n",
      "[ 0.39107126  0.10938402  0.49954474] action_ofnet_proba\n",
      "0.850528226782 cumProbRel\n",
      "[ 0.49484196 -1.29855716  0.80371541] action_ofnet\n",
      "[ 0.39552525  0.06581287  0.5386619 ] action_ofnet_proba\n",
      "1.38832469165 cumProbRel\n",
      "[ 1.15091467 -1.24945176  0.09853703] action_ofnet\n",
      "[ 0.69454509  0.06298462  0.24247035] action_ofnet_proba\n",
      "2.92198211573 cumProbRel\n",
      "[ 1.73422527 -1.1871618  -0.54706335] action_ofnet\n",
      "[ 0.86504334  0.04659031  0.08836633] action_ofnet_proba\n",
      "0.782438893721 cumProbRel\n",
      "[-0.6421755  -1.28920698  1.9313823 ] action_ofnet\n",
      "[ 0.06832472  0.03577467  0.89590061] action_ofnet_proba\n",
      "2.12420448458 cumProbRel\n",
      "2.71485032457 actionRel -1000 rew -2124.20448458 weightedReward\n",
      "0.0393453 meanAcStd\n",
      "------------------------------------------------\n",
      "[ 0.55121678 -0.7350809   0.18386407] action_ofnet\n",
      "[ 0.50790888  0.14033107  0.35176009] action_ofnet_proba\n",
      "1.53911782034 cumProbRel\n",
      "[ 0.71135437 -1.01929986  0.30794546] action_ofnet\n",
      "[ 0.54194456  0.09601548  0.36204001] action_ofnet_proba\n",
      "0.447815579183 cumProbRel\n",
      "[ 0.60683608 -0.97679728  0.36996111] action_ofnet\n",
      "[ 0.50142455  0.10290639  0.39566907] action_ofnet_proba\n",
      "0.536929621304 cumProbRel\n",
      "[-0.2968075  -1.01985228  1.31665969] action_ofnet\n",
      "[ 0.15371706  0.07459465  0.77168834] action_ofnet_proba\n",
      "0.121369937576 cumProbRel\n",
      "[-0.4228853  -1.13183653  1.55472195] action_ofnet\n",
      "[ 0.11471055  0.05645596  0.82883346] action_ofnet_proba\n",
      "0.0207638065918 cumProbRel\n",
      "[-0.64713663 -0.93769825  1.58483493] action_ofnet\n",
      "[ 0.09036637  0.0675799   0.84205377] action_ofnet_proba\n",
      "0.0056859086344 cumProbRel\n",
      "[-0.77752405 -0.8520484   1.62957239] action_ofnet\n",
      "[ 0.07674677  0.07123519  0.85201806] action_ofnet_proba\n",
      "0.00122738414193 cumProbRel\n",
      "[-1.36157858 -0.92879885  2.29037738] action_ofnet\n",
      "[ 0.02433591  0.0375147   0.93814933] action_ofnet_proba\n",
      "0.00348930186086 cumProbRel\n",
      "2.84287676667 actionRel -1000 rew -3.48930186086 weightedReward\n",
      "0.0541308 meanAcStd\n",
      "------------------------------------------------\n",
      "[ 1.50531435 -1.20917392 -0.29614049] action_ofnet\n",
      "[ 0.81215149  0.05379597  0.13405256] action_ofnet_proba\n",
      "0.40621987798 cumProbRel\n",
      "[ 1.16626954 -1.09744787 -0.06882158] action_ofnet\n",
      "[ 0.71696329  0.07453786  0.20849884] action_ofnet_proba\n",
      "0.882559820165 cumProbRel\n",
      "[ 0.89542133 -1.43353689  0.53811544] action_ofnet\n",
      "[ 0.55649674  0.0542012   0.38930202] action_ofnet_proba\n",
      "1.0411585352 cumProbRel\n",
      "[ 0.71166432 -1.13475645  0.42309204] action_ofnet\n",
      "[ 0.52434713  0.08274248  0.39291042] action_ofnet_proba\n",
      "0.261054672119 cumProbRel\n",
      "[ 1.08596003 -1.33958697  0.25362685] action_ofnet\n",
      "[ 0.65639937  0.05804522  0.28555542] action_ofnet_proba\n",
      "0.0459181054731 cumProbRel\n",
      "[ 0.96921045 -1.06278682  0.09357652] action_ofnet\n",
      "[ 0.64613205  0.08469077  0.2691772 ] action_ofnet_proba\n",
      "0.0899065445779 cumProbRel\n",
      "[ 1.49812269 -1.12704647 -0.37107617] action_ofnet\n",
      "[ 0.81521201  0.05904378  0.12574416] action_ofnet_proba\n",
      "0.222099681933 cumProbRel\n",
      "[ 1.51183224 -1.3375349  -0.17429718] action_ofnet\n",
      "[ 0.80443007  0.04656117  0.14900871] action_ofnet_proba\n",
      "0.54140503678 cumProbRel\n",
      "2.43766687133 actionRel 1000 rew 541.40503678 weightedReward\n",
      "0.0370473 meanAcStd\n",
      "------------------------------------------------\n",
      "[-0.11318589 -1.24759638  1.36078215] action_ofnet\n",
      "[ 0.17580441  0.05654075  0.76765478] action_ofnet_proba\n",
      "0.532740625468 cumProbRel\n",
      "[ 0.27656549 -1.38797557  1.1114099 ] action_ofnet\n",
      "[ 0.28622678  0.05417629  0.65959692] action_ofnet_proba\n",
      "1.0648305325 cumProbRel\n",
      "[-0.06561467 -1.29542053  1.36103499] action_ofnet\n",
      "[ 0.18324846  0.05357256  0.763179  ] action_ofnet_proba\n",
      "0.172865755416 cumProbRel\n",
      "[ 0.35738543 -1.44638681  1.08900142] action_ofnet\n",
      "[ 0.30834571  0.0507773   0.64087707] action_ofnet_proba\n",
      "0.161522464457 cumProbRel\n",
      "[-0.02035321 -1.46727109  1.48762441] action_ofnet\n",
      "[ 0.17382599  0.04090028  0.78527373] action_ofnet_proba\n",
      "0.0200191328323 cumProbRel\n",
      "[ 0.4449715  -0.92446685  0.47949535] action_ofnet\n",
      "[ 0.43680012  0.11105631  0.45214349] action_ofnet_proba\n",
      "0.0264980596021 cumProbRel\n",
      "[ 1.14697766 -1.05057251 -0.09640507] action_ofnet\n",
      "[ 0.71455014  0.07936862  0.20608124] action_ofnet_proba\n",
      "0.0063730740992 cumProbRel\n",
      "[ 1.28687847 -1.09636259 -0.19051592] action_ofnet\n",
      "[ 0.75729883  0.06986165  0.17283952] action_ofnet_proba\n",
      "0.00333793661601 cumProbRel\n",
      "0.523756128369 actionRel 1000 rew 3.33793661601 weightedReward\n",
      "0.037047 meanAcStd\n",
      "------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-105.75448802]), 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.rollout(env, silent=False, trNo = 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.choice(ac, 1, p = [0.05, 0.15, .8 ])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.15,  0.05,  0.8 ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Required argument 'file' (pos 2) not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-93e269650080>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisodList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'memoryList.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Required argument 'file' (pos 2) not found"
     ]
    }
   ],
   "source": [
    "env = catcher()\n",
    "memory = []\n",
    "for i in range(10000):\n",
    "    episodList = []\n",
    "    Xprev = env.reset()\n",
    "    end = False\n",
    "    \n",
    "    while not end:\n",
    "        \n",
    "        action = np.random.randint(3)\n",
    "        X, rew, end, _ = env.step([action])\n",
    "        \n",
    "        episodList.append((Xprev, action, rew))\n",
    "        Xprev = X\n",
    "        \n",
    "        #if end:\n",
    "        #    print(rew)\n",
    "    memory.append(episodList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(memory,open('memoryList.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ob, rew, done, _ = env.step(ac)\n",
    "ob = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
