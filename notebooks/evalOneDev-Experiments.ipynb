{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf # pylint: ignore-module\n",
    "import builtins\n",
    "import functools\n",
    "import copy\n",
    "import os\n",
    "\n",
    "# =====================a===========================================\n",
    "# Import all names into common namespace\n",
    "# ================================================================\n",
    "\n",
    "clip = tf.clip_by_value\n",
    "\n",
    "# Make consistent with numpy\n",
    "# ----------------------------------------\n",
    "\n",
    "def sum(x, axis=None, keepdims=False):\n",
    "    return tf.reduce_sum(x, reduction_indices=None if axis is None else [axis], keep_dims = keepdims)\n",
    "def mean(x, axis=None, keepdims=False):\n",
    "    return tf.reduce_mean(x, reduction_indices=None if axis is None else [axis], keep_dims = keepdims)\n",
    "def var(x, axis=None, keepdims=False):\n",
    "    meanx = mean(x, axis=axis, keepdims=keepdims)\n",
    "    return mean(tf.square(x - meanx), axis=axis, keepdims=keepdims)\n",
    "def std(x, axis=None, keepdims=False):\n",
    "    return tf.sqrt(var(x, axis=axis, keepdims=keepdims))\n",
    "def max(x, axis=None, keepdims=False):\n",
    "    return tf.reduce_max(x, reduction_indices=None if axis is None else [axis], keep_dims = keepdims)\n",
    "def min(x, axis=None, keepdims=False):\n",
    "    return tf.reduce_min(x, reduction_indices=None if axis is None else [axis], keep_dims = keepdims)\n",
    "def concatenate(arrs, axis=0):\n",
    "    return tf.concat(axis, arrs)\n",
    "def argmax(x, axis=None):\n",
    "    return tf.argmax(x, dimension=axis)\n",
    "\n",
    "def switch(condition, then_expression, else_expression):\n",
    "    '''Switches between two operations depending on a scalar value (int or bool).\n",
    "    Note that both `then_expression` and `else_expression`\n",
    "    should be symbolic tensors of the *same shape*.\n",
    "\n",
    "    # Arguments\n",
    "        condition: scalar tensor.\n",
    "        then_expression: TensorFlow operation.\n",
    "        else_expression: TensorFlow operation.\n",
    "    '''\n",
    "    x_shape = copy.copy(then_expression.get_shape())\n",
    "    x = tf.cond(tf.cast(condition, 'bool'),\n",
    "                lambda: then_expression,\n",
    "                lambda: else_expression)\n",
    "    x.set_shape(x_shape)\n",
    "    return x\n",
    "\n",
    "# Extras\n",
    "# ----------------------------------------\n",
    "def l2loss(params):\n",
    "    if len(params) == 0:\n",
    "        return tf.constant(0.0)\n",
    "    else:\n",
    "        return tf.add_n([sum(tf.square(p)) for p in params])\n",
    "def lrelu(x, leak=0.2):\n",
    "    f1 = 0.5 * (1 + leak)\n",
    "    f2 = 0.5 * (1 - leak)\n",
    "    return f1 * x + f2 * abs(x)\n",
    "def categorical_sample_logits(X):\n",
    "    # https://github.com/tensorflow/tensorflow/issues/456\n",
    "    U = tf.random_uniform(tf.shape(X))\n",
    "    return argmax(X - tf.log(-tf.log(U)), axis=1)\n",
    "\n",
    "# ================================================================\n",
    "# Global session\n",
    "# ================================================================\n",
    "\n",
    "def get_session():\n",
    "    return tf.get_default_session()\n",
    "\n",
    "def single_threaded_session():\n",
    "    tf_config = tf.ConfigProto(\n",
    "        inter_op_parallelism_threads=1,\n",
    "        intra_op_parallelism_threads=1)\n",
    "    return tf.Session(config=tf_config)\n",
    "\n",
    "ALREADY_INITIALIZED = set()\n",
    "def initialize():\n",
    "    new_variables = set(tf.all_variables()) - ALREADY_INITIALIZED\n",
    "    get_session().run(tf.initialize_variables(new_variables))\n",
    "    ALREADY_INITIALIZED.update(new_variables)\n",
    "\n",
    "\n",
    "def eval(expr, feed_dict=None):\n",
    "    if feed_dict is None: feed_dict = {}\n",
    "    return get_session().run(expr, feed_dict=feed_dict)\n",
    "\n",
    "def set_value(v, val):\n",
    "    get_session().run(v.assign(val))\n",
    "\n",
    "def load_state(fname):\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(get_session(), fname)\n",
    "\n",
    "def save_state(fname):\n",
    "    os.makedirs(os.path.dirname(fname), exist_ok=True)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(get_session(), fname)\n",
    "\n",
    "# ================================================================\n",
    "# Model components\n",
    "# ================================================================\n",
    "\n",
    "\n",
    "def normc_initializer(std=1.0):\n",
    "    def _initializer(shape, dtype=None, partition_info=None): #pylint: disable=W0613\n",
    "        out = np.random.randn(*shape).astype(np.float32)\n",
    "        out *= std / np.sqrt(np.square(out).sum(axis=0, keepdims=True))\n",
    "        return tf.constant(out)\n",
    "    return _initializer\n",
    "\n",
    "def dense(x, size, name, weight_init=None, bias=True):\n",
    "    w = tf.get_variable(name + \"/w\", [x.get_shape()[1], size], initializer=weight_init)\n",
    "    ret = tf.matmul(x, w)\n",
    "    if bias:\n",
    "        b = tf.get_variable(name + \"/b\", [size], initializer=tf.zeros_initializer)\n",
    "        return ret + b\n",
    "    else:\n",
    "        return ret\n",
    "\n",
    "# ================================================================\n",
    "# Basic Stuff\n",
    "# ================================================================\n",
    "\n",
    "def function(inputs, outputs, updates=None, givens=None):\n",
    "    if isinstance(outputs, list):\n",
    "        return _Function(inputs, outputs, updates, givens=givens)\n",
    "    elif isinstance(outputs, dict):\n",
    "        f = _Function(inputs, outputs.values(), updates, givens=givens)\n",
    "        return lambda *inputs : dict(zip(outputs.keys(), f(*inputs)))\n",
    "    else:\n",
    "        f = _Function(inputs, [outputs], updates, givens=givens)\n",
    "        return lambda *inputs : f(*inputs)[0]\n",
    "\n",
    "class _Function(object):\n",
    "    def __init__(self, inputs, outputs, updates, givens, check_nan=False):\n",
    "        assert all(len(i.op.inputs)==0 for i in inputs), \"inputs should all be placeholders\"\n",
    "        self.inputs = inputs\n",
    "        updates = updates or []\n",
    "        self.update_group = tf.group(*updates)\n",
    "        self.outputs_update = list(outputs) + [self.update_group]\n",
    "        self.givens = {} if givens is None else givens\n",
    "        self.check_nan = check_nan\n",
    "    def __call__(self, *inputvals):\n",
    "        assert len(inputvals) == len(self.inputs)\n",
    "        feed_dict = dict(zip(self.inputs, inputvals))\n",
    "        feed_dict.update(self.givens)\n",
    "        results = get_session().run(self.outputs_update, feed_dict=feed_dict)[:-1]\n",
    "        if self.check_nan:\n",
    "            if any(np.isnan(r).any() for r in results):\n",
    "                raise RuntimeError(\"Nan detected\")\n",
    "        return results\n",
    "\n",
    "# ================================================================\n",
    "# Graph traversal\n",
    "# ================================================================\n",
    "\n",
    "VARIABLES = {}\n",
    "\n",
    "# ================================================================\n",
    "# Flat vectors\n",
    "# ================================================================\n",
    "\n",
    "def var_shape(x):\n",
    "    out = [k.value for k in x.get_shape()]\n",
    "    assert all(isinstance(a, int) for a in out), \\\n",
    "        \"shape function assumes that shape is fully known\"\n",
    "    return out\n",
    "\n",
    "def numel(x):\n",
    "    return intprod(var_shape(x))\n",
    "\n",
    "def intprod(x):\n",
    "    return int(np.prod(x))\n",
    "\n",
    "def flatgrad(loss, var_list):\n",
    "    grads = tf.gradients(loss, var_list)\n",
    "    return tf.concat(0, [tf.reshape(grad, [numel(v)])\n",
    "        for (v, grad) in zip(var_list, grads)])\n",
    "\n",
    "class SetFromFlat(object):\n",
    "    def __init__(self, var_list, dtype=tf.float32):\n",
    "        assigns = []\n",
    "        shapes = list(map(var_shape, var_list))\n",
    "        total_size = np.sum([intprod(shape) for shape in shapes])\n",
    "\n",
    "        self.theta = theta = tf.placeholder(dtype,[total_size])\n",
    "        start=0\n",
    "        assigns = []\n",
    "        for (shape,v) in zip(shapes,var_list):\n",
    "            size = intprod(shape)\n",
    "            assigns.append(tf.assign(v, tf.reshape(theta[start:start+size],shape)))\n",
    "            start+=size\n",
    "        assert start == total_size\n",
    "        self.op = tf.group(*assigns)\n",
    "    def __call__(self, theta):\n",
    "        get_session().run(self.op, feed_dict={self.theta:theta})\n",
    "\n",
    "class GetFlat(object):\n",
    "    def __init__(self, var_list):\n",
    "        self.op = tf.concat(0, [tf.reshape(v, [numel(v)]) for v in var_list])\n",
    "    def __call__(self):\n",
    "        return get_session().run(self.op)\n",
    "\n",
    "# ================================================================\n",
    "# Misc\n",
    "# ================================================================\n",
    "\n",
    "def scope_vars(scope, trainable_only):\n",
    "    \"\"\"\n",
    "    Get variables inside a scope\n",
    "    The scope can be specified as a string\n",
    "    \"\"\"\n",
    "    return tf.get_collection(\n",
    "        tf.GraphKeys.TRAINABLE_VARIABLES if trainable_only else tf.GraphKeys.VARIABLES,\n",
    "        scope=scope if isinstance(scope, str) else scope.name\n",
    "    )\n",
    "\n",
    "def in_session(f):\n",
    "    @functools.wraps(f)\n",
    "    def newfunc(*args, **kwargs):\n",
    "        with tf.Session():\n",
    "            f(*args, **kwargs)\n",
    "    return newfunc\n",
    "\n",
    "\n",
    "_PLACEHOLDER_CACHE = {} # name -> (placeholder, dtype, shape)\n",
    "def get_placeholder(name, dtype, shape):\n",
    "    print(\"calling get_placeholder\", name)\n",
    "    if name in _PLACEHOLDER_CACHE:\n",
    "        out, dtype1, shape1 = _PLACEHOLDER_CACHE[name]\n",
    "        assert dtype1==dtype and shape1==shape\n",
    "        return out\n",
    "    else:\n",
    "        out = tf.placeholder(dtype=dtype, shape=shape, name=name)\n",
    "        _PLACEHOLDER_CACHE[name] = (out,dtype,shape)\n",
    "        return out\n",
    "def get_placeholder_cached(name):\n",
    "    return _PLACEHOLDER_CACHE[name][0]\n",
    "\n",
    "def flattenallbut0(x):\n",
    "    return tf.reshape(x, [-1, intprod(x.get_shape().as_list()[1:])])\n",
    "\n",
    "def reset():\n",
    "    global _PLACEHOLDER_CACHE\n",
    "    global VARIABLES\n",
    "    _PLACEHOLDER_CACHE = {}\n",
    "    VARIABLES = {}\n",
    "    tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_session(single_threaded):\n",
    "    import tensorflow as tf\n",
    "    if not single_threaded:\n",
    "        return tf.InteractiveSession()\n",
    "    return tf.InteractiveSession(config=tf.ConfigProto(inter_op_parallelism_threads=1, intra_op_parallelism_threads=1))\n",
    "\n",
    "sess = make_session(single_threaded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#from . import tf_util as U\n",
    "\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class Policy:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.args, self.kwargs = args, kwargs\n",
    "        self.scope = self._initialize(*args, **kwargs)\n",
    "        self.all_variables = tf.get_collection(tf.GraphKeys.VARIABLES, self.scope.name)\n",
    "\n",
    "        self.trainable_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, self.scope.name)\n",
    "        #self.num_params = sum(int(np.prod(v.get_shape().as_list())) for v in self.trainable_variables)\n",
    "        self._setfromflat = SetFromFlat(self.trainable_variables)\n",
    "        self._getflat = GetFlat(self.trainable_variables)\n",
    "\n",
    "        #logger.info('Trainable variables ({} parameters)'.format(self.num_params))\n",
    "        for v in self.trainable_variables:\n",
    "            shp = v.get_shape().as_list()\n",
    "            logger.info('- {} shape:{} size:{}'.format(v.name, shp, np.prod(shp)))\n",
    "        logger.info('All variables')\n",
    "        for v in self.all_variables:\n",
    "            shp = v.get_shape().as_list()\n",
    "            logger.info('- {} shape:{} size:{}'.format(v.name, shp, np.prod(shp)))\n",
    "\n",
    "        placeholders = [tf.placeholder(v.value().dtype, v.get_shape().as_list()) for v in self.all_variables]\n",
    "        self.set_all_vars = function(\n",
    "            inputs=placeholders,\n",
    "            outputs=[],\n",
    "            updates=[tf.group(*[v.assign(p) for v, p in zip(self.all_variables, placeholders)])]\n",
    "        )\n",
    "\n",
    "    def _initialize(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def save(self, filename):\n",
    "        assert filename.endswith('.h5')\n",
    "        with h5py.File(filename, 'w') as f:\n",
    "            for v in self.all_variables:\n",
    "                f[v.name] = v.eval()\n",
    "            # TODO: it would be nice to avoid pickle, but it's convenient to pass Python objects to _initialize\n",
    "            # (like Gym spaces or numpy arrays)\n",
    "            f.attrs['name'] = type(self).__name__\n",
    "            f.attrs['args_and_kwargs'] = np.void(pickle.dumps((self.args, self.kwargs), protocol=-1))\n",
    "\n",
    "    @classmethod\n",
    "    def Load(cls, filename, extra_kwargs=None):\n",
    "        with h5py.File(filename, 'r') as f:\n",
    "            args, kwargs = pickle.loads(f.attrs['args_and_kwargs'].tostring())\n",
    "            if extra_kwargs:\n",
    "                kwargs.update(extra_kwargs)\n",
    "            policy = cls(*args, **kwargs)\n",
    "            policy.set_all_vars(*[f[v.name][...] for v in policy.all_variables])\n",
    "        return policy\n",
    "\n",
    "    # === Rollouts/training ===\n",
    "\n",
    "    def rollout(self, env, *, render=False, timestep_limit=None, save_obs=False, random_stream=None):\n",
    "        \"\"\"\n",
    "        If random_stream is provided, the rollout will take noisy actions with noise drawn from that stream.\n",
    "        Otherwise, no action noise will be added.\n",
    "        \"\"\"\n",
    "        env_timestep_limit = GRID_SIZE - 2\n",
    "        timestep_limit = env_timestep_limit if timestep_limit is None else min(timestep_limit, env_timestep_limit)\n",
    "        rews = []\n",
    "        t = 0\n",
    "        if save_obs:\n",
    "            obs = []\n",
    "        ob = env.reset()\n",
    "        for _ in range(timestep_limit):\n",
    "            ac = self.act(ob[None], random_stream=random_stream)[0]\n",
    "            if save_obs:\n",
    "                obs.append(ob)\n",
    "            ob, rew, done, _ = env.step(ac)\n",
    "            rews.append(rew)\n",
    "            t += 1\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        rews = np.array(rews, dtype=np.float32)\n",
    "        if save_obs:\n",
    "            return rews, t, np.array(obs)\n",
    "        return rews, t\n",
    "\n",
    "    def act(self, ob, random_stream=None):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def set_trainable_flat(self, x):\n",
    "        self._setfromflat(x)\n",
    "\n",
    "    def get_trainable_flat(self):\n",
    "        return self._getflat()\n",
    "\n",
    "    @property\n",
    "    def needs_ob_stat(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def set_ob_stat(self, ob_mean, ob_std):\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Policy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-688c894d1776>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCatchPolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPolicy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mob_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mac_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonlin_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mac_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mac_space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Policy' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class CatchPolicy(Policy):\n",
    "    def _initialize(self, ob_space, ac_space, nonlin_type, hidden_dims, connection_type):\n",
    "        self.ac_space = ac_space\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.connection_type = connection_type\n",
    "\n",
    "        assert len(ob_space.shape) == len(self.ac_space.shape) == 1\n",
    "        #assert np.all(np.isfinite(self.ac_space.low)) and np.all(np.isfinite(self.ac_space.high)), \\\n",
    "        #    'Action bounds required'\n",
    "\n",
    "        self.nonlin = {'tanh': tf.tanh, 'relu': tf.nn.relu,  'elu': tf.nn.elu}[nonlin_type]\n",
    "\n",
    "        with tf.variable_scope(type(self).__name__) as scope:\n",
    "\n",
    "            # Policy network\n",
    "            o = tf.placeholder(tf.float32, [None] + list(ob_space.shape))\n",
    "            a = self._make_net(o)\n",
    "            self._act = function([o], a)\n",
    "        return scope\n",
    "\n",
    "    def _make_net(self, o):\n",
    "        # Process observation\n",
    "        if self.connection_type == 'ff':\n",
    "            x = o\n",
    "            for ilayer, hd in enumerate(self.hidden_dims):\n",
    "                x = self.nonlin(dense(x, hd, 'l{}'.format(ilayer), normc_initializer(1.0)))\n",
    "        else:\n",
    "            raise NotImplementedError(self.connection_type)\n",
    "\n",
    "        # Map to action\n",
    "        scores = dense(x, 3, 'out', normc_initializer(0.01))\n",
    "        sft = tf.nn.softmax(scores)\n",
    "        \n",
    "\n",
    "        #scores_nab = tf.reshape(scores, [-1, 1, 3])\n",
    "        #aidx_na =  tf.argmax(scores_nab, 2)  # 0 ... num_bins-1\n",
    "        a = tf.to_float(sft)\n",
    "        \n",
    "       \n",
    "        return a\n",
    "\n",
    "    def act(self, ob, random_stream=None):\n",
    "        return self._act(ob)\n",
    "\n",
    "    @property\n",
    "    def needs_ob_stat(self):\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def needs_ref_batch(self):\n",
    "        return False\n",
    "\n",
    "    def initialize_from(self, filename, ob_stat=None):\n",
    "        \"\"\"\n",
    "        Initializes weights from another policy, which must have the same architecture (variable names),\n",
    "        but the weight arrays can be smaller than the current policy.\n",
    "        \"\"\"\n",
    "        with h5py.File(filename, 'r') as f:\n",
    "            f_var_names = []\n",
    "            f.visititems(lambda name, obj: f_var_names.append(name) if isinstance(obj, h5py.Dataset) else None)\n",
    "            assert set(v.name for v in self.all_variables) == set(f_var_names), 'Variable names do not match'\n",
    "\n",
    "            init_vals = []\n",
    "            for v in self.all_variables:\n",
    "                shp = v.get_shape().as_list()\n",
    "                f_shp = f[v.name].shape\n",
    "                assert len(shp) == len(f_shp) and all(a >= b for a, b in zip(shp, f_shp)), \\\n",
    "                    'This policy must have more weights than the policy to load'\n",
    "                init_val = v.eval()\n",
    "                # ob_mean and ob_std are initialized with nan, so set them manually\n",
    "                if 'ob_mean' in v.name:\n",
    "                    init_val[:] = 0\n",
    "                    init_mean = init_val\n",
    "                elif 'ob_std' in v.name:\n",
    "                    init_val[:] = 0.001\n",
    "                    init_std = init_val\n",
    "                # Fill in subarray from the loaded policy\n",
    "                init_val[tuple([np.s_[:s] for s in f_shp])] = f[v.name]\n",
    "                init_vals.append(init_val)\n",
    "            self.set_all_vars(*init_vals)\n",
    "\n",
    "        if ob_stat is not None:\n",
    "            ob_stat.set_from_init(init_mean, init_std, init_count=1e5)\n",
    "            \n",
    "GRID_SIZE = 10            \n",
    "            \n",
    "class catcher():\n",
    "    def __init__(self):\n",
    "        self.observation_space = np.zeros((GRID_SIZE, GRID_SIZE)).ravel()\n",
    "        self.action_space = np.array([2])\n",
    "\n",
    "    def step(self, ac):\n",
    "        return self.ep.send(ac)\n",
    "\n",
    "    def reset(self):\n",
    "        self.ep = episode()\n",
    "        S, won, _, _ = self.ep.__next__()\n",
    "        return S\n",
    "    \n",
    "    \n",
    "def episode():\n",
    "    \"\"\"\n",
    "    Coroutine of episode.\n",
    "\n",
    "    Action has to be explicitly send to this coroutine.\n",
    "    \"\"\"\n",
    "    x, y, z = (\n",
    "        np.random.randint(0, GRID_SIZE),  # X of fruit\n",
    "        0,  # Y of dot\n",
    "        np.random.randint(1, GRID_SIZE - 1)  # X of basket\n",
    "    )\n",
    "    while True:\n",
    "        X = np.zeros((GRID_SIZE, GRID_SIZE))  # Reset grid\n",
    "        X[y, x] = 1.  # Draw fruit\n",
    "        bar = range(z - 1, z + 2)\n",
    "        X[-1, bar] = 1.  # Draw basket\n",
    "\n",
    "        # End of game is known when fruit is at penultimate line of grid.\n",
    "        # End represents either a win or a loss\n",
    "        end = int(y >= GRID_SIZE - 2)\n",
    "        rew = 0\n",
    "        if end and x in bar:\n",
    "            rew = 1000\n",
    "        if end and x not in bar:\n",
    "            rew = -1000\n",
    "        if end and x == bar[1]:\n",
    "            rew = 1500\n",
    "            \n",
    "            \n",
    "        \n",
    "        #print(X)\n",
    "        \n",
    "        move = yield X.ravel(), rew, end, None\n",
    "        if end:\n",
    "            break\n",
    "        print(move)\n",
    "        z = np.min([np.max([z + move - 1, 1]), GRID_SIZE - 2])\n",
    "        y += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "GRID_SIZE = 10\n",
    "\n",
    "class catcher():\n",
    "    def __init__(self):\n",
    "        self.observation_space = np.zeros((GRID_SIZE, GRID_SIZE)).ravel()\n",
    "        self.action_space = np.array([2])\n",
    "\n",
    "    def step(self, ac):\n",
    "        return self.ep.send(ac)\n",
    "\n",
    "    def reset(self):\n",
    "        self.ep = episode()\n",
    "        S, won, _, _ = self.ep.__next__()\n",
    "        return S\n",
    "    \n",
    "    \n",
    "def episode():\n",
    "    \"\"\"\n",
    "    Coroutine of episode.\n",
    "\n",
    "    Action has to be explicitly send to this coroutine.\n",
    "    \"\"\"\n",
    "    x, y, z = (\n",
    "        np.random.randint(0, GRID_SIZE),  # X of fruit\n",
    "        0,  # Y of dot\n",
    "        np.random.randint(1, GRID_SIZE - 1)  # X of basket\n",
    "    )\n",
    "    while True:\n",
    "        X = np.zeros((GRID_SIZE, GRID_SIZE))  # Reset grid\n",
    "        X[y, x] = 1.  # Draw fruit\n",
    "        bar = range(z - 1, z + 2)\n",
    "        X[-1, bar] = 1.  # Draw basket\n",
    "\n",
    "        # End of game is known when fruit is at penultimate line of grid.\n",
    "        # End represents either a win or a loss\n",
    "        end = int(y >= GRID_SIZE - 2)\n",
    "        rew = 0\n",
    "        if end and x in bar:\n",
    "            rew = 1000\n",
    "        if end and x not in bar:\n",
    "            rew = -1000\n",
    "        if end and x == bar[1]:\n",
    "            rew = 1500\n",
    "            \n",
    "            \n",
    "        \n",
    "        print(X)\n",
    "        \n",
    "        move = yield X.ravel(), rew, end, None\n",
    "        print(move)\n",
    "        if end:\n",
    "            break\n",
    "\n",
    "        z = np.min([np.max([z + move - 1, 1]), GRID_SIZE - 2])\n",
    "        y += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = catcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  1.  1.  0.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-41964470d8f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-97e77cffaf27>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, ac)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(np.argsort([123, 34, 37]), 1, p = [0.05, 0.15, .8 ])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort([123, 34, 37])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def save_img():\n",
    "    if 'images' not in os.listdir('.'):\n",
    "        os.mkdir('images')\n",
    "    frame = 0\n",
    "    while True:\n",
    "        screen = (yield)\n",
    "        plt.imshow(screen[0], interpolation='none')\n",
    "        plt.savefig('images/%03i.png' % frame)\n",
    "        frame += 1\n",
    "    \n",
    "img_saver = save_img()\n",
    "img_saver.next()\n",
    "\n",
    "for _ in xrange(8):\n",
    "    g = episode()\n",
    "    S, _ = g.next()\n",
    "    img_saver.send(S)\n",
    "    try:\n",
    "        while True:\n",
    "            act = np.argmax(model.predict(S[np.newaxis]), axis=-1)[0] - 1\n",
    "            S, _ = g.send(act)\n",
    "            img_saver.send(S)\n",
    "\n",
    "    except StopIteration:\n",
    "        pass\n",
    "\n",
    "img_saver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = catcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cp = CatchPolicy(env.observation_space ,env.action_space, 'tanh', [100, 100], 'ff')\n",
    "initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snapshot_iter00000_rew50.h5\n",
      "snapshot_iter00005_rew193.h5\n",
      "snapshot_iter00010_rewnan.h5\n",
      "snapshot_iter00015_rew223.h5\n",
      "snapshot_iter00020_rew232.h5\n",
      "snapshot_iter00025_rew231.h5\n",
      "snapshot_iter00030_rew216.h5\n",
      "snapshot_iter00035_rewnan.h5\n",
      "snapshot_iter00040_rew305.h5\n",
      "snapshot_iter00045_rew219.h5\n",
      "snapshot_iter00050_rewnan.h5\n",
      "snapshot_iter00055_rew293.h5\n",
      "snapshot_iter00060_rew240.h5\n",
      "snapshot_iter00065_rew366.h5\n",
      "snapshot_iter00070_rew343.h5\n",
      "snapshot_iter00075_rew198.h5\n",
      "snapshot_iter00080_rew370.h5\n",
      "snapshot_iter00085_rew337.h5\n",
      "snapshot_iter00090_rew378.h5\n",
      "snapshot_iter00095_rew386.h5\n",
      "snapshot_iter00100_rew285.h5\n",
      "snapshot_iter00105_rewnan.h5\n",
      "snapshot_iter00110_rew429.h5\n",
      "snapshot_iter00115_rew273.h5\n",
      "snapshot_iter00120_rew320.h5\n",
      "snapshot_iter00125_rew339.h5\n",
      "snapshot_iter00130_rew351.h5\n",
      "snapshot_iter00135_rewnan.h5\n",
      "snapshot_iter00140_rew421.h5\n",
      "snapshot_iter00145_rew311.h5\n",
      "snapshot_iter00150_rew465.h5\n",
      "snapshot_iter00155_rew393.h5\n",
      "snapshot_iter00160_rew425.h5\n",
      "snapshot_iter00165_rewnan.h5\n",
      "snapshot_iter00170_rewnan.h5\n",
      "snapshot_iter00175_rew412.h5\n",
      "snapshot_iter00180_rew434.h5\n",
      "snapshot_iter00185_rew423.h5\n",
      "snapshot_iter00190_rew303.h5\n",
      "snapshot_iter00195_rew421.h5\n",
      "snapshot_iter00200_rewnan.h5\n",
      "snapshot_iter00205_rew379.h5\n",
      "snapshot_iter00210_rew395.h5\n",
      "snapshot_iter00215_rewnan.h5\n",
      "snapshot_iter00220_rew415.h5\n",
      "snapshot_iter00225_rew385.h5\n",
      "snapshot_iter00230_rew329.h5\n",
      "snapshot_iter00235_rew447.h5\n",
      "snapshot_iter00240_rew412.h5\n",
      "snapshot_iter00245_rew402.h5\n",
      "snapshot_iter00250_rew436.h5\n",
      "snapshot_iter00255_rewnan.h5\n",
      "snapshot_iter00260_rewnan.h5\n",
      "snapshot_iter00265_rew440.h5\n",
      "snapshot_iter00270_rew530.h5\n",
      "snapshot_iter00275_rew398.h5\n",
      "snapshot_iter00280_rew482.h5\n",
      "snapshot_iter00285_rew386.h5\n",
      "snapshot_iter00290_rewnan.h5\n",
      "snapshot_iter00295_rew428.h5\n",
      "snapshot_iter00300_rew385.h5\n",
      "snapshot_iter00305_rew439.h5\n",
      "snapshot_iter00310_rew466.h5\n",
      "snapshot_iter00315_rewnan.h5\n",
      "snapshot_iter00320_rew353.h5\n",
      "snapshot_iter00325_rew444.h5\n",
      "snapshot_iter00330_rew426.h5\n",
      "snapshot_iter00335_rew368.h5\n",
      "snapshot_iter00340_rewnan.h5\n",
      "snapshot_iter00345_rew465.h5\n",
      "snapshot_iter00350_rewnan.h5\n",
      "snapshot_iter00355_rew411.h5\n",
      "snapshot_iter00360_rew505.h5\n",
      "snapshot_iter00365_rew450.h5\n",
      "snapshot_iter00370_rew426.h5\n",
      "snapshot_iter00375_rewnan.h5\n",
      "snapshot_iter00380_rewnan.h5\n",
      "snapshot_iter00385_rew519.h5\n",
      "snapshot_iter00390_rewnan.h5\n",
      "snapshot_iter00395_rew384.h5\n",
      "snapshot_iter00400_rew437.h5\n",
      "snapshot_iter00405_rew487.h5\n",
      "snapshot_iter00410_rewnan.h5\n",
      "snapshot_iter00415_rew423.h5\n",
      "snapshot_iter00420_rewnan.h5\n",
      "snapshot_iter00425_rew320.h5\n",
      "snapshot_iter00430_rew489.h5\n",
      "snapshot_iter00435_rew507.h5\n",
      "snapshot_iter00440_rew382.h5\n",
      "snapshot_iter00445_rew417.h5\n",
      "snapshot_iter00450_rew415.h5\n",
      "snapshot_iter00455_rew517.h5\n",
      "snapshot_iter00460_rew243.h5\n",
      "snapshot_iter00465_rew439.h5\n",
      "snapshot_iter00470_rewnan.h5\n",
      "snapshot_iter00475_rew435.h5\n",
      "snapshot_iter00480_rew451.h5\n",
      "snapshot_iter00485_rew470.h5\n",
      "snapshot_iter00490_rew377.h5\n",
      "snapshot_iter00495_rew354.h5\n",
      "snapshot_iter00500_rewnan.h5\n",
      "snapshot_iter00505_rew438.h5\n",
      "snapshot_iter00510_rew400.h5\n",
      "snapshot_iter00515_rewnan.h5\n",
      "snapshot_iter00520_rew476.h5\n",
      "snapshot_iter00525_rew454.h5\n",
      "snapshot_iter00530_rew426.h5\n",
      "snapshot_iter00535_rew372.h5\n",
      "snapshot_iter00540_rew381.h5\n",
      "snapshot_iter00545_rewnan.h5\n",
      "snapshot_iter00550_rew406.h5\n",
      "snapshot_iter00555_rewnan.h5\n",
      "snapshot_iter00560_rew402.h5\n",
      "snapshot_iter00565_rew403.h5\n",
      "snapshot_iter00570_rewnan.h5\n",
      "snapshot_iter00575_rew398.h5\n",
      "snapshot_iter00580_rew460.h5\n",
      "snapshot_iter00585_rew418.h5\n",
      "snapshot_iter00590_rew465.h5\n",
      "snapshot_iter00595_rew435.h5\n",
      "snapshot_iter00600_rew362.h5\n",
      "snapshot_iter00605_rewnan.h5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "files = os.listdir('/home/alexey/Desktop/es_master_2148/')\n",
    "sorted(files)\n",
    "resRew = {}\n",
    "resPerc = {}\n",
    "for f in sorted(files):\n",
    "    print(f)\n",
    "    cp.initialize_from('/home/alexey/Desktop/es_master_2148/'+f)\n",
    "    tmp = [cp.rollout(env)[0][-1] for i in range(1000)]\n",
    "\n",
    "    resRew[f] = np.mean(tmp)\n",
    "    tmpSer = pd.Series(tmp)\n",
    "\n",
    "    resPerc[f] = tmpSer[tmpSer>0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f07a4c380f0>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9IIgCEWOCL0gCEKR8/8D3qyszrLU2dAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f07a4c344a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp = pd.Series(resPerc).reset_index(drop = True)\n",
    "tmp.index = tmp.index*5\n",
    "(tmp/1000.).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cp.initialize_from('/tmp/es_master_2148/snapshot_iter00325_rew444.h5')\n",
    "#cp.initialize_from('/tmp/es_master_2148/snapshot_iter00370_rew426.h5')\n",
    "cp.initialize_from('/tmp/es_master_2148/snapshot_iter00435_rew507.h5') #94 %\n",
    "#cp.initialize_from('/tmp/es_master_2148/snapshot_iter01125_rew544.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0.,     0.,     0.,     0.,     0.,     0.,     0.,  1000.], dtype=float32),\n",
       " 8)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cp.rollout(env)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "975.5"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = [cp.rollout(env)[0][-1] for i in range(1000)]\n",
    "np.mean(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "979.5"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = [cp.rollout(env)[0][-1] for i in range(1000)]\n",
    "np.mean(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(938,)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tmpSer = pd.Series(tmp)\n",
    "tmpSer[tmpSer>0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tmp = [cp.rollout(env)[0][-1] for i in range(100)]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0.,     0.,     0.,     0.,     0.,     0.,     0.,  1000.], dtype=float32),\n",
       " 8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cp.rollout(env)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def step(self, ac):\n",
    "        return self.ep.send(ac)\n",
    "\n",
    "    def reset(self):\n",
    "        self.ep = episode()\n",
    "        S, won, _, _ = self.ep.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def episodeSampling():\n",
    "    \"\"\"\n",
    "    Coroutine of episode.\n",
    "\n",
    "    Action has to be explicitly send to this coroutine.\n",
    "    \"\"\"\n",
    "    x, y, z = (\n",
    "        np.random.randint(0, GRID_SIZE),  # X of fruit\n",
    "        0,  # Y of dot\n",
    "        np.random.randint(1, GRID_SIZE - 1)  # X of basket\n",
    "    )\n",
    "    while True:\n",
    "        X = np.zeros((GRID_SIZE, GRID_SIZE))  # Reset grid\n",
    "        X[y, x] = 1.  # Draw fruit\n",
    "        bar = range(z - 1, z + 2)\n",
    "        X[-1, bar] = 1.  # Draw basket\n",
    "\n",
    "        # End of game is known when fruit is at penultimate line of grid.\n",
    "        # End represents either a win or a loss\n",
    "        end = int(y >= GRID_SIZE - 2)\n",
    "        rew = 0\n",
    "        if end and x in bar:\n",
    "            rew = 1000\n",
    "        if end and x not in bar:\n",
    "            rew = -1000\n",
    "        if end and x == bar[1]:\n",
    "            rew = 1500\n",
    "\n",
    "        \n",
    "        action = yield X.ravel(), rew, end, (x,  y, z)\n",
    "\n",
    "        move = action\n",
    "\n",
    "        #assert action in [0, 1, 2]\n",
    "        if end:\n",
    "            break\n",
    "\n",
    "        z = np.min([np.max([z + move - 1, 1]), GRID_SIZE - 2])\n",
    "        y += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  1.  1.  0.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  1.  1.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  1.  1.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  1.  1.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  1.  1.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  1.  1.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  1.  1.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  1.  1.  0.  0.]]\n",
      "1000\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  1.  1.  0.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  1.  0.  0.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  1.  1.  0.  0.  0.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  1.  1.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  1.  1.  0.  0.  0.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  1.  0.  0.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  1.  1.  0.  0.  0.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  1.  1.  0.  0.  0.  0.  0.  0.]]\n",
      "1000\n",
      "[[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  1.  0.  0.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  1.  1.  0.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  1.  1.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  1.  1.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  1.  1.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 0.  0.  0.  0.  0.  1.  1.  1.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  1.  1.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  1.  1.  0.  0.]]\n",
      "1000\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  1.  1.  0.  0.  0.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  1.  0.  0.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  1.  1.  0.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  1.  1.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  1.  1.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  1.  1.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  1.  1.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  1.  1.  0.]]\n",
      "1500\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  1.  1.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  1.  1.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  1.  1.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  1.  1.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  1.  1.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  1.  1.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  1.  1.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  1.  1.]]\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "memory = []\n",
    "for i in range(5):\n",
    "    ep = episodeSampling()\n",
    "    episodList = []\n",
    "\n",
    "    Xprev, won, end, (x, y,z) = ep.__next__()\n",
    "    \n",
    "    goodEx = np.random.randint(2)\n",
    "    goodEx = 1\n",
    "    while not end:\n",
    "        \n",
    "        action = np.sign(x -z) + 1\n",
    "        if not goodEx:\n",
    "            action =np.sign(z - x) + 1 \n",
    "        \n",
    "        if action  == 0:\n",
    "           acDistr = np.array([.75, 0.15,.10 ]) \n",
    "        if action  == 1:\n",
    "           acDistr = np.array([.33, 0.33,.33 ]) \n",
    "        if action  == 2:\n",
    "           acDistr = np.array([.1, 0.15,.75 ]) \n",
    "        \n",
    "        if x == z:\n",
    "            acDistr = np.array([.33]*3)\n",
    "            action = np.random.randint(3)\n",
    "        #print(z, x,z-x, action)\n",
    "        print(Xprev.reshape((10, 10)))\n",
    "        if action not in [0, 1, 2]:\n",
    "            print (action)\n",
    "        X, rew, end, (x, y,z) = ep.send(action)\n",
    "        \n",
    "        \n",
    "        episodList.append((Xprev, action, rew, acDistr))\n",
    "        Xprev = X\n",
    "        \n",
    "        if end:\n",
    "            print(rew)\n",
    "    memory.append(episodList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(memory,open('memoryList.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ob, rew, done, _ = env.step(ac)\n",
    "ob = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
