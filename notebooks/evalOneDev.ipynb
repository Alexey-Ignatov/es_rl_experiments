{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf # pylint: ignore-module\n",
    "import builtins\n",
    "import functools\n",
    "import copy\n",
    "import os\n",
    "\n",
    "# ================================================================\n",
    "# Import all names into common namespace\n",
    "# ================================================================\n",
    "\n",
    "clip = tf.clip_by_value\n",
    "\n",
    "# Make consistent with numpy\n",
    "# ----------------------------------------\n",
    "\n",
    "def sum(x, axis=None, keepdims=False):\n",
    "    return tf.reduce_sum(x, reduction_indices=None if axis is None else [axis], keep_dims = keepdims)\n",
    "def mean(x, axis=None, keepdims=False):\n",
    "    return tf.reduce_mean(x, reduction_indices=None if axis is None else [axis], keep_dims = keepdims)\n",
    "def var(x, axis=None, keepdims=False):\n",
    "    meanx = mean(x, axis=axis, keepdims=keepdims)\n",
    "    return mean(tf.square(x - meanx), axis=axis, keepdims=keepdims)\n",
    "def std(x, axis=None, keepdims=False):\n",
    "    return tf.sqrt(var(x, axis=axis, keepdims=keepdims))\n",
    "def max(x, axis=None, keepdims=False):\n",
    "    return tf.reduce_max(x, reduction_indices=None if axis is None else [axis], keep_dims = keepdims)\n",
    "def min(x, axis=None, keepdims=False):\n",
    "    return tf.reduce_min(x, reduction_indices=None if axis is None else [axis], keep_dims = keepdims)\n",
    "def concatenate(arrs, axis=0):\n",
    "    return tf.concat(axis, arrs)\n",
    "def argmax(x, axis=None):\n",
    "    return tf.argmax(x, dimension=axis)\n",
    "\n",
    "def switch(condition, then_expression, else_expression):\n",
    "    '''Switches between two operations depending on a scalar value (int or bool).\n",
    "    Note that both `then_expression` and `else_expression`\n",
    "    should be symbolic tensors of the *same shape*.\n",
    "\n",
    "    # Arguments\n",
    "        condition: scalar tensor.\n",
    "        then_expression: TensorFlow operation.\n",
    "        else_expression: TensorFlow operation.\n",
    "    '''\n",
    "    x_shape = copy.copy(then_expression.get_shape())\n",
    "    x = tf.cond(tf.cast(condition, 'bool'),\n",
    "                lambda: then_expression,\n",
    "                lambda: else_expression)\n",
    "    x.set_shape(x_shape)\n",
    "    return x\n",
    "\n",
    "# Extras\n",
    "# ----------------------------------------\n",
    "def l2loss(params):\n",
    "    if len(params) == 0:\n",
    "        return tf.constant(0.0)\n",
    "    else:\n",
    "        return tf.add_n([sum(tf.square(p)) for p in params])\n",
    "def lrelu(x, leak=0.2):\n",
    "    f1 = 0.5 * (1 + leak)\n",
    "    f2 = 0.5 * (1 - leak)\n",
    "    return f1 * x + f2 * abs(x)\n",
    "def categorical_sample_logits(X):\n",
    "    # https://github.com/tensorflow/tensorflow/issues/456\n",
    "    U = tf.random_uniform(tf.shape(X))\n",
    "    return argmax(X - tf.log(-tf.log(U)), axis=1)\n",
    "\n",
    "# ================================================================\n",
    "# Global session\n",
    "# ================================================================\n",
    "\n",
    "def get_session():\n",
    "    return tf.get_default_session()\n",
    "\n",
    "def single_threaded_session():\n",
    "    tf_config = tf.ConfigProto(\n",
    "        inter_op_parallelism_threads=1,\n",
    "        intra_op_parallelism_threads=1)\n",
    "    return tf.Session(config=tf_config)\n",
    "\n",
    "ALREADY_INITIALIZED = set()\n",
    "def initialize():\n",
    "    new_variables = set(tf.all_variables()) - ALREADY_INITIALIZED\n",
    "    get_session().run(tf.initialize_variables(new_variables))\n",
    "    ALREADY_INITIALIZED.update(new_variables)\n",
    "\n",
    "\n",
    "def eval(expr, feed_dict=None):\n",
    "    if feed_dict is None: feed_dict = {}\n",
    "    return get_session().run(expr, feed_dict=feed_dict)\n",
    "\n",
    "def set_value(v, val):\n",
    "    get_session().run(v.assign(val))\n",
    "\n",
    "def load_state(fname):\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(get_session(), fname)\n",
    "\n",
    "def save_state(fname):\n",
    "    os.makedirs(os.path.dirname(fname), exist_ok=True)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(get_session(), fname)\n",
    "\n",
    "# ================================================================\n",
    "# Model components\n",
    "# ================================================================\n",
    "\n",
    "\n",
    "def normc_initializer(std=1.0):\n",
    "    def _initializer(shape, dtype=None, partition_info=None): #pylint: disable=W0613\n",
    "        out = np.random.randn(*shape).astype(np.float32)\n",
    "        out *= std / np.sqrt(np.square(out).sum(axis=0, keepdims=True))\n",
    "        return tf.constant(out)\n",
    "    return _initializer\n",
    "\n",
    "def dense(x, size, name, weight_init=None, bias=True):\n",
    "    w = tf.get_variable(name + \"/w\", [x.get_shape()[1], size], initializer=weight_init)\n",
    "    ret = tf.matmul(x, w)\n",
    "    if bias:\n",
    "        b = tf.get_variable(name + \"/b\", [size], initializer=tf.zeros_initializer)\n",
    "        return ret + b\n",
    "    else:\n",
    "        return ret\n",
    "\n",
    "# ================================================================\n",
    "# Basic Stuff\n",
    "# ================================================================\n",
    "\n",
    "def function(inputs, outputs, updates=None, givens=None):\n",
    "    if isinstance(outputs, list):\n",
    "        return _Function(inputs, outputs, updates, givens=givens)\n",
    "    elif isinstance(outputs, dict):\n",
    "        f = _Function(inputs, outputs.values(), updates, givens=givens)\n",
    "        return lambda *inputs : dict(zip(outputs.keys(), f(*inputs)))\n",
    "    else:\n",
    "        f = _Function(inputs, [outputs], updates, givens=givens)\n",
    "        return lambda *inputs : f(*inputs)[0]\n",
    "\n",
    "class _Function(object):\n",
    "    def __init__(self, inputs, outputs, updates, givens, check_nan=False):\n",
    "        assert all(len(i.op.inputs)==0 for i in inputs), \"inputs should all be placeholders\"\n",
    "        self.inputs = inputs\n",
    "        updates = updates or []\n",
    "        self.update_group = tf.group(*updates)\n",
    "        self.outputs_update = list(outputs) + [self.update_group]\n",
    "        self.givens = {} if givens is None else givens\n",
    "        self.check_nan = check_nan\n",
    "    def __call__(self, *inputvals):\n",
    "        assert len(inputvals) == len(self.inputs)\n",
    "        feed_dict = dict(zip(self.inputs, inputvals))\n",
    "        feed_dict.update(self.givens)\n",
    "        results = get_session().run(self.outputs_update, feed_dict=feed_dict)[:-1]\n",
    "        if self.check_nan:\n",
    "            if any(np.isnan(r).any() for r in results):\n",
    "                raise RuntimeError(\"Nan detected\")\n",
    "        return results\n",
    "\n",
    "# ================================================================\n",
    "# Graph traversal\n",
    "# ================================================================\n",
    "\n",
    "VARIABLES = {}\n",
    "\n",
    "# ================================================================\n",
    "# Flat vectors\n",
    "# ================================================================\n",
    "\n",
    "def var_shape(x):\n",
    "    out = [k.value for k in x.get_shape()]\n",
    "    assert all(isinstance(a, int) for a in out), \\\n",
    "        \"shape function assumes that shape is fully known\"\n",
    "    return out\n",
    "\n",
    "def numel(x):\n",
    "    return intprod(var_shape(x))\n",
    "\n",
    "def intprod(x):\n",
    "    return int(np.prod(x))\n",
    "\n",
    "def flatgrad(loss, var_list):\n",
    "    grads = tf.gradients(loss, var_list)\n",
    "    return tf.concat(0, [tf.reshape(grad, [numel(v)])\n",
    "        for (v, grad) in zip(var_list, grads)])\n",
    "\n",
    "class SetFromFlat(object):\n",
    "    def __init__(self, var_list, dtype=tf.float32):\n",
    "        assigns = []\n",
    "        shapes = list(map(var_shape, var_list))\n",
    "        total_size = np.sum([intprod(shape) for shape in shapes])\n",
    "\n",
    "        self.theta = theta = tf.placeholder(dtype,[total_size])\n",
    "        start=0\n",
    "        assigns = []\n",
    "        for (shape,v) in zip(shapes,var_list):\n",
    "            size = intprod(shape)\n",
    "            assigns.append(tf.assign(v, tf.reshape(theta[start:start+size],shape)))\n",
    "            start+=size\n",
    "        assert start == total_size\n",
    "        self.op = tf.group(*assigns)\n",
    "    def __call__(self, theta):\n",
    "        get_session().run(self.op, feed_dict={self.theta:theta})\n",
    "\n",
    "class GetFlat(object):\n",
    "    def __init__(self, var_list):\n",
    "        self.op = tf.concat(0, [tf.reshape(v, [numel(v)]) for v in var_list])\n",
    "    def __call__(self):\n",
    "        return get_session().run(self.op)\n",
    "\n",
    "# ================================================================\n",
    "# Misc\n",
    "# ================================================================\n",
    "\n",
    "def scope_vars(scope, trainable_only):\n",
    "    \"\"\"\n",
    "    Get variables inside a scope\n",
    "    The scope can be specified as a string\n",
    "    \"\"\"\n",
    "    return tf.get_collection(\n",
    "        tf.GraphKeys.TRAINABLE_VARIABLES if trainable_only else tf.GraphKeys.VARIABLES,\n",
    "        scope=scope if isinstance(scope, str) else scope.name\n",
    "    )\n",
    "\n",
    "def in_session(f):\n",
    "    @functools.wraps(f)\n",
    "    def newfunc(*args, **kwargs):\n",
    "        with tf.Session():\n",
    "            f(*args, **kwargs)\n",
    "    return newfunc\n",
    "\n",
    "\n",
    "_PLACEHOLDER_CACHE = {} # name -> (placeholder, dtype, shape)\n",
    "def get_placeholder(name, dtype, shape):\n",
    "    print(\"calling get_placeholder\", name)\n",
    "    if name in _PLACEHOLDER_CACHE:\n",
    "        out, dtype1, shape1 = _PLACEHOLDER_CACHE[name]\n",
    "        assert dtype1==dtype and shape1==shape\n",
    "        return out\n",
    "    else:\n",
    "        out = tf.placeholder(dtype=dtype, shape=shape, name=name)\n",
    "        _PLACEHOLDER_CACHE[name] = (out,dtype,shape)\n",
    "        return out\n",
    "def get_placeholder_cached(name):\n",
    "    return _PLACEHOLDER_CACHE[name][0]\n",
    "\n",
    "def flattenallbut0(x):\n",
    "    return tf.reshape(x, [-1, intprod(x.get_shape().as_list()[1:])])\n",
    "\n",
    "def reset():\n",
    "    global _PLACEHOLDER_CACHE\n",
    "    global VARIABLES\n",
    "    _PLACEHOLDER_CACHE = {}\n",
    "    VARIABLES = {}\n",
    "    tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def episode():\n",
    "    \"\"\"\n",
    "    Coroutine of episode.\n",
    "\n",
    "    Action has to be explicitly send to this coroutine.\n",
    "    \"\"\"\n",
    "    x, y, z = (\n",
    "        np.random.randint(0, GRID_SIZE),  # X of fruit\n",
    "        0,  # Y of dot\n",
    "        np.random.randint(1, GRID_SIZE - 1)  # X of basket\n",
    "    )\n",
    "    while True:\n",
    "        X = np.zeros((GRID_SIZE, GRID_SIZE))  # Reset grid\n",
    "        X[y, x] = 1.  # Draw fruit\n",
    "        bar = range(z - 1, z + 2)\n",
    "        X[-1, bar] = 1.  # Draw basket\n",
    "\n",
    "        # End of game is known when fruit is at penultimate line of grid.\n",
    "        # End represents either a win or a loss\n",
    "        end = int(y >= GRID_SIZE - 2)\n",
    "        rew = 0\n",
    "        if end and x in bar:\n",
    "            rew = 1000\n",
    "        if end and x not in bar:\n",
    "            rew = -1000\n",
    "        if end and x == bar[1]:\n",
    "            rew = 1500\n",
    "\n",
    "        move = yield X.ravel(), rew, end, None\n",
    "        if end:\n",
    "            break\n",
    "        z = np.min([np.max([z + move - 1, 1]), GRID_SIZE - 2])\n",
    "        y += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_session(single_threaded):\n",
    "    import tensorflow as tf\n",
    "    if not single_threaded:\n",
    "        return tf.InteractiveSession()\n",
    "    return tf.InteractiveSession(config=tf.ConfigProto(inter_op_parallelism_threads=1, intra_op_parallelism_threads=1))\n",
    "\n",
    "sess = make_session(single_threaded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from random import sample as rsample\n",
    "#from . import tf_util as U\n",
    "\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class Policy:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.args, self.kwargs = args, kwargs\n",
    "        self.scope = self._initialize(*args, **kwargs)\n",
    "        self.all_variables = tf.get_collection(tf.GraphKeys.VARIABLES, self.scope.name)\n",
    "\n",
    "        self.trainable_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, self.scope.name)\n",
    "        #self.num_params = sum(int(np.prod(v.get_shape().as_list())) for v in self.trainable_variables)\n",
    "        self._setfromflat = SetFromFlat(self.trainable_variables)\n",
    "        self._getflat = GetFlat(self.trainable_variables)\n",
    "\n",
    "        #logger.info('Trainable variables ({} parameters)'.format(self.num_params))\n",
    "        for v in self.trainable_variables:\n",
    "            shp = v.get_shape().as_list()\n",
    "            logger.info('- {} shape:{} size:{}'.format(v.name, shp, np.prod(shp)))\n",
    "        logger.info('All variables')\n",
    "        for v in self.all_variables:\n",
    "            shp = v.get_shape().as_list()\n",
    "            logger.info('- {} shape:{} size:{}'.format(v.name, shp, np.prod(shp)))\n",
    "\n",
    "        placeholders = [tf.placeholder(v.value().dtype, v.get_shape().as_list()) for v in self.all_variables]\n",
    "        self.set_all_vars = function(\n",
    "            inputs=placeholders,\n",
    "            outputs=[],\n",
    "            updates=[tf.group(*[v.assign(p) for v, p in zip(self.all_variables, placeholders)])]\n",
    "        )\n",
    "\n",
    "    def _initialize(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def save(self, filename):\n",
    "        assert filename.endswith('.h5')\n",
    "        with h5py.File(filename, 'w') as f:\n",
    "            for v in self.all_variables:\n",
    "                f[v.name] = v.eval()\n",
    "            # TODO: it would be nice to avoid pickle, but it's convenient to pass Python objects to _initialize\n",
    "            # (like Gym spaces or numpy arrays)\n",
    "            f.attrs['name'] = type(self).__name__\n",
    "            f.attrs['args_and_kwargs'] = np.void(pickle.dumps((self.args, self.kwargs), protocol=-1))\n",
    "\n",
    "    @classmethod\n",
    "    def Load(cls, filename, extra_kwargs=None):\n",
    "        with h5py.File(filename, 'r') as f:\n",
    "            args, kwargs = pickle.loads(f.attrs['args_and_kwargs'].tostring())\n",
    "            if extra_kwargs:\n",
    "                kwargs.update(extra_kwargs)\n",
    "            policy = cls(*args, **kwargs)\n",
    "            policy.set_all_vars(*[f[v.name][...] for v in policy.all_variables])\n",
    "        return policy\n",
    "\n",
    "    # === Rollouts/training ===\n",
    "\n",
    "    def rollout(self, env, *, render=False, timestep_limit=None, save_obs=False, random_stream=None):\n",
    "        \"\"\"\n",
    "        If random_stream is provided, the rollout will take noisy actions with noise drawn from that stream.\n",
    "        Otherwise, no action noise will be added.\n",
    "        \"\"\"\n",
    "        #env_timestep_limit = env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')\n",
    "        #timestep_limit = env_timestep_limit if timestep_limit is None else min(timestep_limit, env_timestep_limit)\n",
    "        timestep_limit = GRID_SIZE\n",
    "        rews = []\n",
    "        t = 0\n",
    "        if save_obs:\n",
    "            obs = []\n",
    "        ob = env.reset()\n",
    "        for _ in range(timestep_limit):\n",
    "            ac = self.act(ob[None], random_stream=random_stream)[0]\n",
    "            print(ac)\n",
    "            if save_obs:\n",
    "                obs.append(ob)\n",
    "            ob, rew, done, _ = env.step(np.argmax(ac))\n",
    "            rews.append(rew)\n",
    "            t += 1\n",
    "            if render:\n",
    "                env.render()\n",
    "            if done:\n",
    "                break\n",
    "        rews = np.array(rews, dtype=np.float32)\n",
    "        if save_obs:\n",
    "            return rews, t, np.array(obs)\n",
    "\n",
    "        return rews, t\n",
    "\n",
    "    def act(self, ob, random_stream=None):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def set_trainable_flat(self, x):\n",
    "        self._setfromflat(x)\n",
    "\n",
    "    def get_trainable_flat(self):\n",
    "        return self._getflat()\n",
    "\n",
    "    @property\n",
    "    def needs_ob_stat(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def set_ob_stat(self, ob_mean, ob_std):\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.5,   9. ,  13.5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std([np.array([1, 2, 3]), np.array([10, 20, 30])], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "class CatchPolicy(Policy):\n",
    "    def _initialize(self, ob_space, ac_space, nonlin_type, hidden_dims, connection_type):\n",
    "        self.ac_space = ac_space\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.connection_type = connection_type\n",
    "\n",
    "        assert len(ob_space.shape) == len(self.ac_space.shape) == 1\n",
    "        #assert np.all(np.isfinite(self.ac_space.low)) and np.all(np.isfinite(self.ac_space.high)), \\\n",
    "        #    'Action bounds required'\n",
    "\n",
    "        self.nonlin = {'tanh': tf.tanh, 'relu': tf.nn.relu,  'elu': tf.nn.elu}[nonlin_type]\n",
    "\n",
    "        with tf.variable_scope(type(self).__name__) as scope:\n",
    "\n",
    "            # Policy network\n",
    "            o = tf.placeholder(tf.float32, [None] + list(ob_space.shape))\n",
    "            a = self._make_net(o)\n",
    "            self._act = function([o], a)\n",
    "        return scope\n",
    "\n",
    "    def _make_net(self, o):\n",
    "        # Process observation\n",
    "        if self.connection_type == 'ff':\n",
    "            x = o\n",
    "            for ilayer, hd in enumerate(self.hidden_dims):\n",
    "                x = self.nonlin(dense(x, hd, 'l{}'.format(ilayer), normc_initializer(1.0)))\n",
    "        else:\n",
    "            raise NotImplementedError(self.connection_type)\n",
    "\n",
    "        # Map to action\n",
    "        scores = dense(x, 3, 'out', normc_initializer(0.01))\n",
    "        #scores_nab = tf.reshape(scores, [-1, 1, 3])\n",
    "        #aidx_na =  tf.argmax(scores_nab, 2)  # 0 ... num_bins-1\n",
    "        a = tf.to_float(scores)\n",
    "        \n",
    "       \n",
    "        return a\n",
    "\n",
    "    def act(self, ob, random_stream=None):\n",
    "        return self._act(ob)\n",
    "\n",
    "    @property\n",
    "    def needs_ob_stat(self):\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def needs_ref_batch(self):\n",
    "        return False\n",
    "\n",
    "    def initialize_from(self, filename, ob_stat=None):\n",
    "        \"\"\"\n",
    "        Initializes weights from another policy, which must have the same architecture (variable names),\n",
    "        but the weight arrays can be smaller than the current policy.\n",
    "        \"\"\"\n",
    "        with h5py.File(filename, 'r') as f:\n",
    "            f_var_names = []\n",
    "            f.visititems(lambda name, obj: f_var_names.append(name) if isinstance(obj, h5py.Dataset) else None)\n",
    "            assert set(v.name for v in self.all_variables) == set(f_var_names), 'Variable names do not match'\n",
    "\n",
    "            init_vals = []\n",
    "            for v in self.all_variables:\n",
    "                shp = v.get_shape().as_list()\n",
    "                f_shp = f[v.name].shape\n",
    "                assert len(shp) == len(f_shp) and all(a >= b for a, b in zip(shp, f_shp)), \\\n",
    "                    'This policy must have more weights than the policy to load'\n",
    "                init_val = v.eval()\n",
    "                # ob_mean and ob_std are initialized with nan, so set them manually\n",
    "                if 'ob_mean' in v.name:\n",
    "                    init_val[:] = 0\n",
    "                    init_mean = init_val\n",
    "                elif 'ob_std' in v.name:\n",
    "                    init_val[:] = 0.001\n",
    "                    init_std = init_val\n",
    "                # Fill in subarray from the loaded policy\n",
    "                init_val[tuple([np.s_[:s] for s in f_shp])] = f[v.name]\n",
    "                init_vals.append(init_val)\n",
    "            self.set_all_vars(*init_vals)\n",
    "\n",
    "        if ob_stat is not None:\n",
    "            ob_stat.set_from_init(init_mean, init_std, init_count=1e5)\n",
    "            \n",
    "GRID_SIZE = 10            \n",
    "            \n",
    "class catcher():\n",
    "    def __init__(self):\n",
    "        #self.memory = pickle.load(open('memoryList.pickle', 'rb'))\n",
    "        \n",
    "        self.observation_space = np.zeros((GRID_SIZE, GRID_SIZE)).ravel()\n",
    "        self.action_space = np.array([2])\n",
    "\n",
    "    def get_trajectory(self):\n",
    "        return rsample(self.memory, 1)[0]\n",
    "\n",
    "    def reset(self):\n",
    "        self.ep = episode()\n",
    "        S, won, _, _ = self.ep.__next__()\n",
    "        return S\n",
    "    def isOffPolisy(self):\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "c = catcher()\n",
    "c.get_trajectory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def save_img():\n",
    "    if 'images' not in os.listdir('.'):\n",
    "        os.mkdir('images')\n",
    "    frame = 0\n",
    "    while True:\n",
    "        screen = (yield)\n",
    "        plt.imshow(screen[0], interpolation='none')\n",
    "        plt.savefig('images/%03i.png' % frame)\n",
    "        frame += 1\n",
    "    \n",
    "img_saver = save_img()\n",
    "img_saver.next()\n",
    "\n",
    "for _ in xrange(8):\n",
    "    g = episode()\n",
    "    S, _ = g.next()\n",
    "    img_saver.send(S)\n",
    "    try:\n",
    "        while True:\n",
    "            act = np.argmax(model.predict(S[np.newaxis]), axis=-1)[0] - 1\n",
    "            S, _ = g.send(act)\n",
    "            img_saver.send(S)\n",
    "\n",
    "    except StopIteration:\n",
    "        pass\n",
    "\n",
    "img_saver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = catcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:From <ipython-input-1-6dfdf3ae096f>:83 in initialize.: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      "WARNING:tensorflow:From <ipython-input-1-6dfdf3ae096f>:84 in initialize.: initialize_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "cp = CatchPolicy(env.observation_space ,env.action_space, 'tanh', [100, 100], 'ff')\n",
    "initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp.initialize_from('/home/aignatov/snapshot.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.08447915 -0.04455882  0.03031181]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'catcher' object has no attribute 'step'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-33835b00f268>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-6c25c4493aca>\u001b[0m in \u001b[0;36mrollout\u001b[0;34m(self, env, render, timestep_limit, save_obs, random_stream)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msave_obs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0mrews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'catcher' object has no attribute 'step'"
     ]
    }
   ],
   "source": [
    "cp.rollout(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14093 acStd\n",
      "[ 1.46028852 -1.32450557 -0.13578297] ac\n",
      "-1.14093446732 cummWeight\n",
      "0.802629 acStd\n",
      "[ 1.13267899 -0.63035822 -0.50232077] ac\n",
      "-1.94356334209 cummWeight\n",
      "0.688156 acStd\n",
      "[ 0.91608196 -0.74252784 -0.17355403] ac\n",
      "-1.255407691 cummWeight\n",
      "1.01828 acStd\n",
      "[ 1.38821411 -1.02574873 -0.36246532] ac\n",
      "-0.237128138542 cummWeight\n",
      "1.11315 acStd\n",
      "[ 1.55261123 -0.55109864 -1.00151265] ac\n",
      "-1.35028266907 cummWeight\n",
      "1.00032 acStd\n",
      "[ 1.3729564  -0.98175496 -0.39120144] ac\n",
      "-2.35059773922 cummWeight\n",
      "1.25064 acStd\n",
      "[ 1.74405801 -1.12664986 -0.61740828] ac\n",
      "-3.60123372078 cummWeight\n",
      "0.985896 acStd\n",
      "[-0.18519044 -1.10417771  1.28936815] ac\n",
      "-2.61533749104 cummWeight\n",
      "1000 rew -2615.33749104 weightedReward\n",
      "0.0424416 meanAcStd\n",
      "------------------------------------------------\n",
      "0.998166 acStd\n",
      "[ 1.15237141 -1.28225553  0.12988421] ac\n",
      "0.998166441917 cummWeight\n",
      "1.03619 acStd\n",
      "[ 1.20061135 -1.32792389  0.1273125 ] ac\n",
      "-0.0380218029022 cummWeight\n",
      "1.25089 acStd\n",
      "[ 1.52144563 -1.54237831  0.02093262] ac\n",
      "1.21286666393 cummWeight\n",
      "0.989024 acStd\n",
      "[ 1.27650976 -1.13337541 -0.14313434] ac\n",
      "0.223842799664 cummWeight\n",
      "0.980125 acStd\n",
      "[ 1.35240197 -0.93930441 -0.41309759] ac\n",
      "1.20396751165 cummWeight\n",
      "0.967268 acStd\n",
      "[ 1.36396778 -0.59196264 -0.77200514] ac\n",
      "0.236699938774 cummWeight\n",
      "0.704392 acStd\n",
      "[ 0.09168237 -0.90488034  0.81319797] ac\n",
      "0.941092133522 cummWeight\n",
      "1.07395 acStd\n",
      "[-0.53502226 -0.96348906  1.4985112 ] ac\n",
      "2.01504051685 cummWeight\n",
      "-1000 rew -2015.04051685 weightedReward\n",
      "0.053784 meanAcStd\n",
      "------------------------------------------------\n",
      "1.1805 acStd\n",
      "[-0.29009706 -1.27876794  1.56886494] ac\n",
      "1.18050003052 cummWeight\n",
      "0.668039 acStd\n",
      "[ 0.03824307 -0.83662856  0.7983855 ] ac\n",
      "0.512460768223 cummWeight\n",
      "1.28581 acStd\n",
      "[-0.75030839 -1.05932653  1.80963516] ac\n",
      "1.79826980829 cummWeight\n",
      "1.04472 acStd\n",
      "[ 0.03442507 -1.29637671  1.26195145] ac\n",
      "0.75355309248 cummWeight\n",
      "0.780079 acStd\n",
      "[ 0.08116106 -0.99338919  0.91222817] ac\n",
      "1.53363204002 cummWeight\n",
      "1.00878 acStd\n",
      "[-0.28917244 -1.06526923  1.35444176] ac\n",
      "2.54241538048 cummWeight\n",
      "0.997799 acStd\n",
      "[ 1.37810755 -0.9517656  -0.42634201] ac\n",
      "1.54461687803 cummWeight\n",
      "1.03427 acStd\n",
      "[ 1.45165646 -0.57057077 -0.88108557] ac\n",
      "0.510342657566 cummWeight\n",
      "-1000 rew -510.342657566 weightedReward\n",
      "0.0476575 meanAcStd\n",
      "------------------------------------------------\n",
      "1.22666 acStd\n",
      "[ 1.70354426 -1.13546717 -0.56807697] ac\n",
      "-1.22665679455 cummWeight\n",
      "1.27291 acStd\n",
      "[ 1.49684787 -1.61446893  0.11762094] ac\n",
      "-2.49956655502 cummWeight\n",
      "1.16724 acStd\n",
      "[ 1.45777833 -1.39958775 -0.05819054] ac\n",
      "-3.66680681705 cummWeight\n",
      "1.1463 acStd\n",
      "[ 1.59286094 -1.05738783 -0.53547299] ac\n",
      "-2.52050745487 cummWeight\n",
      "0.779053 acStd\n",
      "[ 0.33055544 -1.07546222  0.74490684] ac\n",
      "-3.29956072569 cummWeight\n",
      "0.611567 acStd\n",
      "[ 0.18856119 -0.82527614  0.63671494] ac\n",
      "-3.91112756729 cummWeight\n",
      "0.953413 acStd\n",
      "[-0.72852147 -0.6183061   1.34682763] ac\n",
      "-4.86454087496 cummWeight\n",
      "0.84286 acStd\n",
      "[-0.47691533 -0.70760489  1.18452013] ac\n",
      "-4.02168047428 cummWeight\n",
      "-1000 rew 4021.68047428 weightedReward\n",
      "0.0544469 meanAcStd\n",
      "------------------------------------------------\n",
      "1.44254 acStd\n",
      "[ 2.02407527 -1.23275876 -0.79131657] ac\n",
      "-1.44253909588 cummWeight\n",
      "1.02748 acStd\n",
      "[ 1.36781669 -1.10861838 -0.25919822] ac\n",
      "-0.415059924126 cummWeight\n",
      "0.798782 acStd\n",
      "[ 0.94372129 -1.00956011  0.06583884] ac\n",
      "-1.2138415575 cummWeight\n",
      "1.03661 acStd\n",
      "[ 1.46023738 -0.61784434 -0.84239316] ac\n",
      "-2.25044667721 cummWeight\n",
      "0.773861 acStd\n",
      "[ 1.0843339  -0.67045289 -0.41388115] ac\n",
      "-1.47658526897 cummWeight\n",
      "0.830572 acStd\n",
      "[ 1.14497912 -0.79951704 -0.34546202] ac\n",
      "-2.30715715885 cummWeight\n",
      "0.875309 acStd\n",
      "[ 1.2126168  -0.82176125 -0.39085552] ac\n",
      "-3.18246644735 cummWeight\n",
      "1.21485 acStd\n",
      "[ 1.7176764  -0.82739621 -0.89028019] ac\n",
      "-4.39731842279 cummWeight\n",
      "10000 rew -43973.1842279 weightedReward\n",
      "0.0447248 meanAcStd\n",
      "------------------------------------------------\n",
      "1.17503 acStd\n",
      "[ 1.55901492 -1.27764714 -0.28136775] ac\n",
      "1.17502868176 cummWeight\n",
      "0.999832 acStd\n",
      "[ 1.38551903 -0.93719399 -0.44832498] ac\n",
      "0.175196886063 cummWeight\n",
      "0.950539 acStd\n",
      "[ 1.32105219 -0.87593621 -0.44511601] ac\n",
      "1.12573552132 cummWeight\n",
      "0.99259 acStd\n",
      "[ 1.16195941 -1.26306403  0.10110454] ac\n",
      "0.133145868778 cummWeight\n",
      "0.882032 acStd\n",
      "[ 1.21442366 -0.85389644 -0.36052716] ac\n",
      "-0.748886585236 cummWeight\n",
      "0.968352 acStd\n",
      "[ 1.36923957 -0.7057609  -0.66347867] ac\n",
      "0.219465851784 cummWeight\n",
      "0.724142 acStd\n",
      "[ 0.06735802 -0.91864783  0.85128987] ac\n",
      "0.943607985973 cummWeight\n",
      "1.30748 acStd\n",
      "[-0.65136552 -1.17300451  1.82436991] ac\n",
      "2.25109177828 cummWeight\n",
      "-1000 rew -2251.09177828 weightedReward\n",
      "0.0441774 meanAcStd\n",
      "------------------------------------------------\n",
      "0.962197 acStd\n",
      "[ 1.24791276 -1.09381855 -0.15409428] ac\n",
      "-0.962197184563 cummWeight\n",
      "0.772096 acStd\n",
      "[ 1.06635594 -0.7365551  -0.32980087] ac\n",
      "-0.190101087093 cummWeight\n",
      "0.876973 acStd\n",
      "[ 1.16059434 -0.95896441 -0.20162985] ac\n",
      "-1.06707441807 cummWeight\n",
      "1.00965 acStd\n",
      "[ 1.25646174 -1.21564686 -0.0408148 ] ac\n",
      "-0.0574277639389 cummWeight\n",
      "0.994973 acStd\n",
      "[ 1.36992574 -0.96323448 -0.40669122] ac\n",
      "0.937545418739 cummWeight\n",
      "1.09235 acStd\n",
      "[ 1.54456532 -0.79613078 -0.74843448] ac\n",
      "-0.154800772667 cummWeight\n",
      "0.816866 acStd\n",
      "[ 0.07598295 -1.03627706  0.96029413] ac\n",
      "0.66206485033 cummWeight\n",
      "1.4749 acStd\n",
      "[-0.7347703  -1.32320309  2.05797315] ac\n",
      "2.13696676493 cummWeight\n",
      "-1000 rew -2136.96676493 weightedReward\n",
      "0.0391628 meanAcStd\n",
      "------------------------------------------------\n",
      "1.7239 acStd\n",
      "[ 2.34826374 -1.7415843  -0.60667938] ac\n",
      "-1.72390246391 cummWeight\n",
      "1.13719 acStd\n",
      "[ 1.53353345 -1.18629134 -0.34724215] ac\n",
      "-0.586714506149 cummWeight\n",
      "0.919311 acStd\n",
      "[ 1.15820301 -1.09059238 -0.06761058] ac\n",
      "-1.50602531433 cummWeight\n",
      "1.04953 acStd\n",
      "[ 1.46735382 -0.54018414 -0.92716968] ac\n",
      "-2.555560112 cummWeight\n",
      "0.707737 acStd\n",
      "[ 0.96272588 -0.71844196 -0.24428399] ac\n",
      "-3.26329702139 cummWeight\n",
      "0.700215 acStd\n",
      "[ 0.96527594 -0.67403376 -0.29124215] ac\n",
      "-2.56308251619 cummWeight\n",
      "0.73793 acStd\n",
      "[ 1.02229798 -0.69278675 -0.3295112 ] ac\n",
      "-1.82515203953 cummWeight\n",
      "1.02418 acStd\n",
      "[ 1.448089  -0.6975373 -0.7505517] ac\n",
      "-2.84933423996 cummWeight\n",
      "10000 rew -28493.3423996 weightedReward\n",
      "0.0530512 meanAcStd\n",
      "------------------------------------------------\n",
      "1.05556 acStd\n",
      "[-0.42052561 -1.03017831  1.45070386] ac\n",
      "1.05556476116 cummWeight\n",
      "0.888602 acStd\n",
      "[-0.17413458 -0.99074399  1.16487861] ac\n",
      "1.94416642189 cummWeight\n",
      "1.18456 acStd\n",
      "[-0.78772759 -0.88652724  1.67425489] ac\n",
      "3.12873029709 cummWeight\n",
      "1.04592 acStd\n",
      "[ 0.03446482 -1.2978735   1.26340854] ac\n",
      "2.08280730247 cummWeight\n",
      "0.78098 acStd\n",
      "[ 0.08125477 -0.99453616  0.9132815 ] ac\n",
      "1.30182766914 cummWeight\n",
      "1.00995 acStd\n",
      "[-0.28950632 -1.06649923  1.35600555] ac\n",
      "0.291879534721 cummWeight\n",
      "0.998951 acStd\n",
      "[ 1.37969875 -0.95286453 -0.42683429] ac\n",
      "-0.707071065903 cummWeight\n",
      "1.03547 acStd\n",
      "[ 1.45333254 -0.57122958 -0.88210291] ac\n",
      "-1.74253940582 cummWeight\n",
      "-1000 rew 1742.53940582 weightedReward\n",
      "0.0476025 meanAcStd\n",
      "------------------------------------------------\n",
      "1.59053 acStd\n",
      "[ 2.24406958 -1.25549948 -0.98857009] ac\n",
      "-1.59053432941 cummWeight\n",
      "1.12227 acStd\n",
      "[ 1.5538789  -1.05682778 -0.49705115] ac\n",
      "-0.468262195587 cummWeight\n",
      "0.845 acStd\n",
      "[ 0.92877954 -1.11559248  0.18681294] ac\n",
      "-1.31326258183 cummWeight\n",
      "0.973284 acStd\n",
      "[ 1.37103832 -0.5801031  -0.79093528] ac\n",
      "-2.28654640913 cummWeight\n",
      "0.72659 acStd\n",
      "[ 1.01809704 -0.62949806 -0.3885991 ] ac\n",
      "-3.01313626766 cummWeight\n",
      "0.779836 acStd\n",
      "[ 1.07503772 -0.7506783  -0.32435939] ac\n",
      "-2.23330014944 cummWeight\n",
      "0.821841 acStd\n",
      "[ 1.13854373 -0.77156371 -0.36697999] ac\n",
      "-3.05514091253 cummWeight\n",
      "1.14064 acStd\n",
      "[ 1.6127516  -0.77685446 -0.83589715] ac\n",
      "-4.19578319788 cummWeight\n",
      "10000 rew -41957.8319788 weightedReward\n",
      "0.0476346 meanAcStd\n",
      "------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-11818.89179349]), 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.rollout(env, silent=False, trNo = 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.choice(ac, 1, p = [0.05, 0.15, .8 ])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.15,  0.05,  0.8 ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Required argument 'file' (pos 2) not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-93e269650080>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisodList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'memoryList.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Required argument 'file' (pos 2) not found"
     ]
    }
   ],
   "source": [
    "env = catcher()\n",
    "memory = []\n",
    "for i in range(10000):\n",
    "    episodList = []\n",
    "    Xprev = env.reset()\n",
    "    end = False\n",
    "    \n",
    "    while not end:\n",
    "        \n",
    "        action = np.random.randint(3)\n",
    "        X, rew, end, _ = env.step([action])\n",
    "        \n",
    "        episodList.append((Xprev, action, rew))\n",
    "        Xprev = X\n",
    "        \n",
    "        #if end:\n",
    "        #    print(rew)\n",
    "    memory.append(episodList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(memory,open('memoryList.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ob, rew, done, _ = env.step(ac)\n",
    "ob = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
